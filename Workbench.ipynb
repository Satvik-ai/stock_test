{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Deploying Iris-detection model using Vertex AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb"
   },
   "source": [
    "### Install Vertex AI SDK for Python and other required packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1fd00fa70a2a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform==1.126.0 (from -r requirements.txt (line 1))\n",
      "  Using cached google_cloud_aiplatform-1.126.0-py2.py3-none-any.whl.metadata (45 kB)\n",
      "Collecting pyarrow==21.0.0 (from -r requirements.txt (line 2))\n",
      "  Using cached pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting mlflow==3.5.1 (from -r requirements.txt (line 3))\n",
      "  Using cached mlflow-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pandas==2.3.3 (from -r requirements.txt (line 4))\n",
      "  Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy==2.1.3 (from -r requirements.txt (line 5))\n",
      "  Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn==1.7.2 (from -r requirements.txt (line 6))\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib==1.5.2 (from -r requirements.txt (line 7))\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting feast==0.56.0 (from -r requirements.txt (line 8))\n",
      "  Using cached feast-0.56.0-py2.py3-none-any.whl.metadata (37 kB)\n",
      "Collecting dvc==3.63.0 (from -r requirements.txt (line 9))\n",
      "  Using cached dvc-3.63.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting dvc-gs==3.0.2 (from -r requirements.txt (line 10))\n",
      "  Using cached dvc_gs-3.0.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting gcsfs==2025.10.0 (from -r requirements.txt (line 11))\n",
      "  Using cached gcsfs-2025.10.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pytest==8.4.2 (from -r requirements.txt (line 12))\n",
      "  Using cached pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting click==8.1.8 (from -r requirements.txt (line 13))\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf==6.31.1 (from -r requirements.txt (line 14))\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting atpublic==5.1 (from -r requirements.txt (line 15))\n",
      "  Using cached atpublic-5.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting rich==13.9.4 (from -r requirements.txt (line 16))\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting matplotlib==3.10.0 (from -r requirements.txt (line 17))\n",
      "  Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting opentelemetry-sdk==1.37.0 (from -r requirements.txt (line 18))\n",
      "  Using cached opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting scipy==1.15.0 (from -r requirements.txt (line 19))\n",
      "  Using cached scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting packaging>=14.3 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-cloud-storage<4.0.0,>=1.32.0 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_storage-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_bigquery-3.38.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_resource_manager-1.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting shapely<3.0.0 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached shapely-2.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting google-genai<2.0.0,>=1.37.0 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_genai-1.49.0-py3-none-any.whl.metadata (46 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting typing_extensions (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting docstring_parser<1 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mlflow-skinny==3.5.1 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached mlflow_skinny-3.5.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.5.1 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached mlflow_tracing-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Flask<4 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached alembic-1.17.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cryptography<47,>=43.0.0 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas==2.3.3->-r requirements.txt (line 4))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.3.3->-r requirements.txt (line 4))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.3.3->-r requirements.txt (line 4))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.7.2->-r requirements.txt (line 6))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.10.0->-r requirements.txt (line 17))\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.10.0->-r requirements.txt (line 17))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.10.0->-r requirements.txt (line 17))\n",
      "  Using cached fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.0->-r requirements.txt (line 17))\n",
      "  Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib==3.10.0->-r requirements.txt (line 17))\n",
      "  Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.10.0->-r requirements.txt (line 17))\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting colorama<1,>=0.3.9 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting dill~=0.3.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting Jinja2<4,>=2 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting mmh3 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached mmh3-5.2.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pygments<3,>=2.12.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting PyYAML<7,>=5.4.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting requests (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tabulate<1,>=0.8.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tenacity<9,>=7 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<1,>=0.10.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm<5,>=4 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typeguard>=4.0.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting fastapi>=0.68.0 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached fastapi-0.121.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn<=0.34.0,>=0.30.6 (from uvicorn[standard]<=0.34.0,>=0.30.6->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting uvicorn-worker (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached uvicorn_worker-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dask>=2024.2.1 (from dask[dataframe]>=2024.2.1->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached dask-2025.11.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting prometheus_client (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting psutil (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Collecting bigtree>=0.19.2 (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached bigtree-1.0.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyjwt (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting attrs>=22.2.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting celery (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached celery-5.5.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting configobj>=5.0.9 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting distro>=1.3 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting dpath<3,>=2.1.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dpath-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting dulwich (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dulwich-0.24.8-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting dvc-data<3.17,>=3.16.2 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dvc_data-3.16.12-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting dvc-http>=2.29.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dvc_http-2.32.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting dvc-objects (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dvc_objects-5.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting dvc-render<2,>=1.0.1 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dvc_render-1.0.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dvc-studio-client<1,>=0.21 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dvc_studio_client-0.22.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting dvc-task<1,>=0.3.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dvc_task-0.40.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Collecting flatten_dict<1,>=0.4.1 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting flufl.lock<9,>=8.1.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached flufl_lock-8.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting fsspec>=2024.2.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting funcy>=1.14 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting grandalf<1,>=0.7 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting gto<2,>=1.6.0 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached gto-1.9.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting hydra-core>=1.1 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting iterative-telemetry>=0.0.7 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached iterative_telemetry-0.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting kombu (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached kombu-5.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting networkx>=2.5 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting omegaconf (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pathspec>=0.10.3 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting platformdirs<5,>=3.1.1 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydot>=1.2.4 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached pydot-4.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pygtrie>=2.3.2 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting ruamel.yaml>=0.17.11 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting scmrepo<4,>=3.5.2 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached scmrepo-3.5.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting shortuuid>=0.5 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting shtab<2,>=1.3.4 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting tomlkit>=0.11.1 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting voluptuous>=0.11.7 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting zc.lockfile>=1.2.1 (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached zc_lockfile-4.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting decorator>4.1.2 (from gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-auth-oauthlib (from gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached google_auth_oauthlib-1.2.3-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting exceptiongroup>=1 (from pytest==8.4.2->-r requirements.txt (line 12))\n",
      "  Using cached exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting iniconfig>=1 (from pytest==8.4.2->-r requirements.txt (line 12))\n",
      "  Using cached iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest==8.4.2->-r requirements.txt (line 12))\n",
      "  Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tomli>=1 (from pytest==8.4.2->-r requirements.txt (line 12))\n",
      "  Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich==13.9.4->-r requirements.txt (line 16))\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting opentelemetry-api==1.37.0 (from opentelemetry-sdk==1.37.0->-r requirements.txt (line 18))\n",
      "  Using cached opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk==1.37.0->-r requirements.txt (line 18))\n",
      "  Using cached opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting cffi>=2.0.0 (from cryptography<47,>=43.0.0->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting dictdiffer>=0.8.1 (from dvc-data<3.17,>=3.16.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached dictdiffer-0.9.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting diskcache>=5.2.1 (from dvc-data<3.17,>=3.16.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sqltrie<1,>=0.11.0 (from dvc-data<3.17,>=3.16.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached sqltrie-0.11.2-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting orjson<4,>=3 (from dvc-data<3.17,>=3.16.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting billiard<5.0,>=4.2.1 (from celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached billiard-4.2.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting kombu (from dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached kombu-5.5.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting vine<6.0,>=5.1.0 (from celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached vine-5.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting click-didyoumean>=0.3.0 (from celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached click_didyoumean-0.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting click-repl>=0.2.0 (from celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached click_repl-0.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting click-plugins>=1.1.1 (from celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi>=0.68.0->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi>=0.68.0->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from Flask<4->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask<4->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting six<2.0,>=1.12 (from flatten_dict<1,>=0.4.1->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_cloud_core-2.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached grpc_google_iam_v1-0.14.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0.0,>=1.1.3 (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_crc32c-1.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting entrypoints (from gto<2,>=1.6.0->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pydantic-settings>=2 (from gto<2,>=1.6.0->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting semver>=2.13.0 (from gto<2,>=1.6.0->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting typer>=0.4.1 (from gto<2,>=1.6.0->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting certifi (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.5.1->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting amqp<6.0.0,>=5.1.1 (from kombu->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached amqp-5.3.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pygit2>=1.14.0 (from scmrepo<4,>=3.5.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached pygit2-1.18.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting asyncssh<3,>=2.13.1 (from scmrepo<4,>=3.5.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached asyncssh-2.21.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp-retry>=2.5.0 (from scmrepo<4,>=3.5.2->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]<=0.34.0,>=0.30.6->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]<=0.34.0,>=0.30.6->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]<=0.34.0,>=0.30.6->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting pycparser (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow==3.5.1->-r requirements.txt (line 3))\n",
      "  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting prompt-toolkit>=3.0.36 (from click-repl>=0.2.0->celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting partd>=1.4.0 (from dask>=2024.2.1->dask[dataframe]>=2024.2.1->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting toolz>=0.10.0 (from dask>=2024.2.1->dask[dataframe]>=2024.2.1->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting appdirs (from iterative-telemetry>=0.0.7->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from iterative-telemetry>=0.0.7->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich==13.9.4->-r requirements.txt (line 16))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting locket (from partd>=1.4.0->dask>=2024.2.1->dask[dataframe]>=2024.2.1->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting wcwidth (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings>=2->gto<2,>=1.6.0->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.11->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached ruamel.yaml.clib-0.2.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mypy>=0.910 (from SQLAlchemy[mypy]>1->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached mypy-1.18.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting mypy_extensions>=1.0.0 (from mypy>=0.910->SQLAlchemy[mypy]>1->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.4.1->gto<2,>=1.6.0->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting setuptools (from zc.lockfile>=1.2.1->dvc==3.63.0->-r requirements.txt (line 9))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-cloud-aiplatform==1.126.0->-r requirements.txt (line 1))\n",
      "  Using cached google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2025.10.0->-r requirements.txt (line 11))\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached rpds_py-0.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "INFO: pip is looking at multiple versions of uvicorn-worker to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting uvicorn-worker (from feast==0.56.0->-r requirements.txt (line 8))\n",
      "  Using cached uvicorn_worker-0.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached google_cloud_aiplatform-1.126.0-py2.py3-none-any.whl (8.1 MB)\n",
      "Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Using cached pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "Using cached mlflow-3.5.1-py3-none-any.whl (8.8 MB)\n",
      "Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached scipy-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached feast-0.56.0-py2.py3-none-any.whl (7.7 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached dvc-3.63.0-py3-none-any.whl (466 kB)\n",
      "Using cached dvc_gs-3.0.2-py3-none-any.whl (10 kB)\n",
      "Using cached gcsfs-2025.10.0-py2.py3-none-any.whl (36 kB)\n",
      "Using cached pytest-8.4.2-py3-none-any.whl (365 kB)\n",
      "Using cached atpublic-5.1-py3-none-any.whl (5.2 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached mlflow_skinny-3.5.1-py3-none-any.whl (2.3 MB)\n",
      "Using cached opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Using cached mlflow_tracing-3.5.1-py3-none-any.whl (1.3 MB)\n",
      "Using cached opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Using cached pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached alembic-1.17.1-py3-none-any.whl (247 kB)\n",
      "Using cached cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached dpath-2.2.0-py3-none-any.whl (17 kB)\n",
      "Using cached dvc_data-3.16.12-py3-none-any.whl (78 kB)\n",
      "Using cached dvc_objects-5.1.2-py3-none-any.whl (33 kB)\n",
      "Using cached dvc_render-1.0.2-py3-none-any.whl (22 kB)\n",
      "Using cached dvc_studio_client-0.22.0-py3-none-any.whl (16 kB)\n",
      "Using cached dvc_task-0.40.2-py3-none-any.whl (21 kB)\n",
      "Using cached celery-5.5.3-py3-none-any.whl (438 kB)\n",
      "Using cached billiard-4.2.2-py3-none-any.whl (86 kB)\n",
      "Using cached fastapi-0.121.0-py3-none-any.whl (109 kB)\n",
      "Using cached flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Using cached flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Using cached flufl_lock-8.2.0-py3-none-any.whl (11 kB)\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Using cached google_cloud_bigquery-3.38.0-py3-none-any.whl (259 kB)\n",
      "Using cached google_cloud_core-2.5.0-py3-none-any.whl (29 kB)\n",
      "Using cached google_cloud_resource_manager-1.15.0-py3-none-any.whl (397 kB)\n",
      "Using cached google_cloud_storage-3.5.0-py3-none-any.whl (289 kB)\n",
      "Using cached google_crc32c-1.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38 kB)\n",
      "Using cached google_genai-1.49.0-py3-none-any.whl (256 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Using cached grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached grpc_google_iam_v1-0.14.3-py3-none-any.whl (32 kB)\n",
      "Using cached grpcio-1.76.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "Using cached grpcio_status-1.76.0-py3-none-any.whl (14 kB)\n",
      "Using cached gto-1.9.0-py3-none-any.whl (45 kB)\n",
      "Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached kombu-5.5.4-py3-none-any.whl (210 kB)\n",
      "Using cached vine-5.1.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached amqp-5.3.1-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Using cached orjson-3.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached platformdirs-4.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached scmrepo-3.5.2-py3-none-any.whl (73 kB)\n",
      "Using cached asyncssh-2.21.1-py3-none-any.whl (375 kB)\n",
      "Using cached shapely-2.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "Using cached shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Using cached sqltrie-0.11.2-py3-none-any.whl (17 kB)\n",
      "Using cached starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Using cached websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Using cached aiohttp-3.13.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached bigtree-1.0.3-py3-none-any.whl (111 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
      "Using cached click_didyoumean-0.3.1-py3-none-any.whl (3.6 kB)\n",
      "Using cached click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Using cached click_repl-0.3.0-py3-none-any.whl (10 kB)\n",
      "Using cached configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dask-2025.11.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "Using cached dictdiffer-0.9.0-py2.py3-none-any.whl (16 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached dulwich-0.24.8-cp310-cp310-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Using cached dvc_http-2.32.0-py3-none-any.whl (12 kB)\n",
      "Using cached exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Using cached fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
      "Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Using cached funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
      "Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached httptools-0.7.1-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (440 kB)\n",
      "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached iterative_telemetry-0.0.10-py3-none-any.whl (10 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Using cached psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Using cached pydot-4.0.1-py3-none-any.whl (37 kB)\n",
      "Using cached pygit2-1.18.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.5 MB)\n",
      "Using cached pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "Using cached ruamel.yaml.clib-0.2.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (721 kB)\n",
      "Using cached semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Using cached shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached mypy-1.18.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Using cached toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "Using cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Using cached typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached uvloop-0.22.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "Using cached voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
      "Using cached watchfiles-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached zc_lockfile-4.0-py3-none-any.whl (9.1 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached google_auth_oauthlib-1.2.3-py3-none-any.whl (19 kB)\n",
      "Using cached google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.28.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (382 kB)\n",
      "Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Using cached mmh3-5.2.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (101 kB)\n",
      "Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached uvicorn_worker-0.3.0-py3-none-any.whl (5.3 kB)\n",
      "Using cached wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pytz, pygtrie, funcy, dictdiffer, appdirs, antlr4-python3-runtime, zipp, websockets, wcwidth, voluptuous, vine, uvloop, urllib3, tzdata, typing_extensions, tqdm, toolz, tomlkit, tomli, toml, threadpoolctl, tenacity, tabulate, sqlparse, sniffio, smmap, six, shtab, shortuuid, shellingham, setuptools, semver, ruamel.yaml.clib, rpds-py, PyYAML, python-dotenv, pyparsing, pyjwt, pygments, pycparser, pyasn1, pyarrow, psutil, protobuf, propcache, prometheus_client, pluggy, platformdirs, pillow, pathspec, packaging, orjson, oauthlib, numpy, networkx, mypy_extensions, mmh3, mdurl, markupsafe, locket, kiwisolver, joblib, itsdangerous, iniconfig, idna, httptools, h11, greenlet, graphql-core, google-crc32c, fsspec, frozenlist, fonttools, filelock, entrypoints, dvc-render, dpath, docstring_parser, distro, diskcache, dill, decorator, cycler, configobj, colorama, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, billiard, bigtree, attrs, atpublic, async-timeout, annotated-types, annotated-doc, aiohappyeyeballs, zc.lockfile, werkzeug, uvicorn, typing-inspection, typeguard, sqltrie, sqlalchemy, shapely, scipy, ruamel.yaml, rsa, requests, referencing, python-dateutil, pydot, pydantic-core, pyasn1-modules, proto-plus, prompt-toolkit, partd, opentelemetry-proto, omegaconf, mypy, multidict, markdown-it-py, Mako, Jinja2, importlib_metadata, httpcore, gunicorn, grpcio, graphql-relay, grandalf, googleapis-common-protos, google-resumable-media, gitdb, flufl.lock, flatten_dict, exceptiongroup, dvc-objects, dulwich, contourpy, click-plugins, click-didyoumean, cffi, amqp, aiosignal, yarl, uvicorn-worker, scikit-learn, rich, requests-oauthlib, pytest, pygit2, pydantic, pandas, opentelemetry-api, matplotlib, kombu, jsonschema-specifications, iterative-telemetry, hydra-core, grpcio-status, graphene, google-auth, gitpython, Flask, dvc-studio-client, dvc-data, docker, dask, cryptography, click-repl, anyio, alembic, watchfiles, typer, starlette, pydantic-settings, opentelemetry-semantic-conventions, jsonschema, httpx, grpc-google-iam-v1, google-auth-oauthlib, google-api-core, Flask-CORS, databricks-sdk, celery, asyncssh, aiohttp, opentelemetry-sdk, google-genai, google-cloud-core, fastapi, dvc-task, aiohttp-retry, scmrepo, mlflow-tracing, mlflow-skinny, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, feast, dvc-http, mlflow, gto, google-cloud-aiplatform, gcsfs, dvc, dvc-gs\n",
      "\u001b[2K  Attempting uninstall: pytz\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\n",
      "\u001b[2K    Uninstalling pytz-2025.2:\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
      "\u001b[2K  Attempting uninstall: pygtrie\u001b[0m \u001b[32m  0/209\u001b[0m [pytz]\n",
      "\u001b[2K    Found existing installation: pygtrie 2.5.00m \u001b[32m  0/209\u001b[0m [pytz]\n",
      "\u001b[2K    Uninstalling pygtrie-2.5.0:\u001b[0m \u001b[32m  0/209\u001b[0m [pytz]\n",
      "\u001b[2K      Successfully uninstalled pygtrie-2.5.0\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K  Attempting uninstall: funcy\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K    Found existing installation: funcy 2.0\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K    Uninstalling funcy-2.0:\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K      Successfully uninstalled funcy-2.0\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K  Attempting uninstall: dictdiffer\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K    Found existing installation: dictdiffer 0.9.0\u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K    Uninstalling dictdiffer-0.9.0:\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K      Successfully uninstalled dictdiffer-0.9.0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K  Attempting uninstall: appdirs\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K    Found existing installation: appdirs 1.4.40m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K    Uninstalling appdirs-1.4.4:\u001b[0m \u001b[32m  1/209\u001b[0m [pygtrie]\n",
      "\u001b[2K      Successfully uninstalled appdirs-1.4.4\u001b[0m \u001b[32m  4/209\u001b[0m [appdirs]\n",
      "\u001b[2K  Attempting uninstall: antlr4-python3-runtime\u001b[0m \u001b[32m  4/209\u001b[0m [appdirs]\n",
      "\u001b[2K    Found existing installation: antlr4-python3-runtime 4.9.32m  4/209\u001b[0m [appdirs]\n",
      "\u001b[2K    Uninstalling antlr4-python3-runtime-4.9.3:\u001b[0m \u001b[32m  4/209\u001b[0m [appdirs]\n",
      "\u001b[2K      Successfully uninstalled antlr4-python3-runtime-4.9.3[32m  4/209\u001b[0m [appdirs]\n",
      "\u001b[2K  Attempting uninstall: zipp\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K    Found existing installation: zipp 3.23.0\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K    Uninstalling zipp-3.23.0:\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K      Successfully uninstalled zipp-3.23.0\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K  Attempting uninstall: websockets\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K    Found existing installation: websockets 15.0.1\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K    Uninstalling websockets-15.0.1:\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K      Successfully uninstalled websockets-15.0.1\u001b[0m \u001b[32m  5/209\u001b[0m [antlr4-python3-runtime]\n",
      "\u001b[2K  Attempting uninstall: wcwidth\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: wcwidth 0.2.14\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling wcwidth-0.2.14:\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled wcwidth-0.2.14\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: voluptuous\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: voluptuous 0.15.2\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling voluptuous-0.15.2:\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled voluptuous-0.15.2\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: vine\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: vine 5.1.0\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling vine-5.1.0:\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K      Successfully uninstalled vine-5.1.0\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K  Attempting uninstall: uvloop\u001b[0m \u001b[32m  7/209\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: uvloop 0.22.1\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K    Uninstalling uvloop-0.22.1:\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K      Successfully uninstalled uvloop-0.22.1\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K  Attempting uninstall: urllib3\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0\u001b[0m \u001b[32m 11/209\u001b[0m [uvloop]\n",
      "\u001b[2K  Attempting uninstall: tzdata\u001b[0m \u001b[32m 12/209\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: tzdata 2025.2\u001b[0m \u001b[32m 12/209\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling tzdata-2025.2:\u001b[0m \u001b[32m 12/209\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.2\u001b[0m \u001b[32m 12/209\u001b[0m [urllib3]\n",
      "\u001b[2K  Attempting uninstall: typing_extensions\u001b[0m \u001b[32m 13/209\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0\u001b[0m \u001b[32m 13/209\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:\u001b[0m \u001b[32m 13/209\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdmm\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: toolz\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Found existing installation: toolz 1.1.0\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Uninstalling toolz-1.1.0:\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K      Successfully uninstalled toolz-1.1.0\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: tomlkit\u001b[0m \u001b[32m 14/209\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Found existing installation: tomlkit 0.13.3\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]sions]\n",
      "\u001b[2K    Uninstalling tomlkit-0.13.3:\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K      Successfully uninstalled tomlkit-0.13.3\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K  Attempting uninstall: tomli\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K    Found existing installation: tomli 2.3.0\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K    Uninstalling tomli-2.3.0:\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K      Successfully uninstalled tomli-2.3.0\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K  Attempting uninstall: toml\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K    Found existing installation: toml 0.10.2\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K    Uninstalling toml-0.10.2:\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K      Successfully uninstalled toml-0.10.2\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K  Attempting uninstall: threadpoolctl\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K    Found existing installation: threadpoolctl 3.6.0\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K    Uninstalling threadpoolctl-3.6.0:\u001b[0m \u001b[32m 17/209\u001b[0m [tomlkit]\n",
      "\u001b[2K      Successfully uninstalled threadpoolctl-3.6.0\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K  Attempting uninstall: tenacity\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K    Found existing installation: tenacity 8.5.0\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K    Uninstalling tenacity-8.5.0:\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K      Successfully uninstalled tenacity-8.5.0\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K  Attempting uninstall: tabulate\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K    Found existing installation: tabulate 0.9.0\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K    Uninstalling tabulate-0.9.0:\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K      Successfully uninstalled tabulate-0.9.0\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K  Attempting uninstall: sqlparse\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K    Found existing installation: sqlparse 0.5.3\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K    Uninstalling sqlparse-0.5.3:\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K      Successfully uninstalled sqlparse-0.5.3\u001b[0m \u001b[32m 20/209\u001b[0m [threadpoolctl]\n",
      "\u001b[2K  Attempting uninstall: sniffio\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]]\n",
      "\u001b[2K    Found existing installation: sniffio 1.3.1\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K    Uninstalling sniffio-1.3.1:\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K      Successfully uninstalled sniffio-1.3.1\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K  Attempting uninstall: smmap\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K    Found existing installation: smmap 5.0.2\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K    Uninstalling smmap-5.0.2:\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K      Successfully uninstalled smmap-5.0.2\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K  Attempting uninstall: six\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K    Found existing installation: six 1.17.0\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K    Uninstalling six-1.17.0:\u001b[0m \u001b[32m 23/209\u001b[0m [sqlparse]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0\u001b[0m \u001b[32m 26/209\u001b[0m [six]]\n",
      "\u001b[2K  Attempting uninstall: shtab\u001b[0m \u001b[32m 26/209\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: shtab 1.7.2\u001b[0m \u001b[32m 26/209\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling shtab-1.7.2:\u001b[0m \u001b[32m 26/209\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled shtab-1.7.2\u001b[0m \u001b[32m 26/209\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: shortuuid\u001b[0m \u001b[32m 27/209\u001b[0m [shtab]\n",
      "\u001b[2K    Found existing installation: shortuuid 1.0.13\u001b[0m \u001b[32m 27/209\u001b[0m [shtab]\n",
      "\u001b[2K    Uninstalling shortuuid-1.0.13:\u001b[0m \u001b[32m 27/209\u001b[0m [shtab]\n",
      "\u001b[2K      Successfully uninstalled shortuuid-1.0.13\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K  Attempting uninstall: shellingham\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K    Found existing installation: shellingham 1.5.4\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K    Uninstalling shellingham-1.5.4:\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K      Successfully uninstalled shellingham-1.5.4\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K  Attempting uninstall: setuptools\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:\u001b[0m \u001b[32m 28/209\u001b[0m [shortuuid]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0\u001b[0m \u001b[32m 30/209\u001b[0m [setuptools]\n",
      "\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 30/209\u001b[0m [setuptools]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~distutils_hack'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: semver\n",
      "\u001b[2K    Found existing installation: semver 3.0.4\u001b[0m \u001b[32m 30/209\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling semver-3.0.4:\u001b[0m \u001b[32m 30/209\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled semver-3.0.4\u001b[0m \u001b[32m 30/209\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: ruamel.yaml.clib\u001b[0m \u001b[32m 31/209\u001b[0m [semver]\n",
      "\u001b[2K    Found existing installation: ruamel.yaml.clib 0.2.14\u001b[0m \u001b[32m 31/209\u001b[0m [semver]\n",
      "\u001b[2K    Uninstalling ruamel.yaml.clib-0.2.14:\u001b[0m \u001b[32m 31/209\u001b[0m [semver]\n",
      "\u001b[2K      Successfully uninstalled ruamel.yaml.clib-0.2.14\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K  Attempting uninstall: rpds-py\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K    Found existing installation: rpds-py 0.28.0\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K    Uninstalling rpds-py-0.28.0:\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K      Successfully uninstalled rpds-py-0.28.0\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K  Attempting uninstall: PyYAML\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3\u001b[0m \u001b[32m 32/209\u001b[0m [ruamel.yaml.clib]\n",
      "\u001b[2K  Attempting uninstall: python-dotenv\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML].clib]\n",
      "\u001b[2K    Found existing installation: python-dotenv 1.2.1\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K    Uninstalling python-dotenv-1.2.1:\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K      Successfully uninstalled python-dotenv-1.2.1\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K  Attempting uninstall: pyparsing\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K    Found existing installation: pyparsing 3.2.5\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K    Uninstalling pyparsing-3.2.5:\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K      Successfully uninstalled pyparsing-3.2.5\u001b[0m \u001b[32m 34/209\u001b[0m [PyYAML]\n",
      "\u001b[2K  Attempting uninstall: pyjwt[90m\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: PyJWT 2.10.1\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling PyJWT-2.10.1:\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled PyJWT-2.10.1\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: pygments\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K    Found existing installation: Pygments 2.19.2\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K    Uninstalling Pygments-2.19.2:\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K      Successfully uninstalled Pygments-2.19.2\u001b[0m \u001b[32m 36/209\u001b[0m [pyparsing]\n",
      "\u001b[2K  Attempting uninstall: pycparserm\u001b[0m \u001b[32m 38/209\u001b[0m [pygments]\n",
      "\u001b[2K    Found existing installation: pycparser 2.23\u001b[0m \u001b[32m 38/209\u001b[0m [pygments]\n",
      "\u001b[2K    Uninstalling pycparser-2.23:\u001b[0m \u001b[32m 38/209\u001b[0m [pygments]\n",
      "\u001b[2K      Successfully uninstalled pycparser-2.23\u001b[0m \u001b[32m 38/209\u001b[0m [pygments]\n",
      "\u001b[2K  Attempting uninstall: pyasn1\u001b[0m \u001b[32m 38/209\u001b[0m [pygments]\n",
      "\u001b[2K    Found existing installation: pyasn1 0.6.1\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K    Uninstalling pyasn1-0.6.1:\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K      Successfully uninstalled pyasn1-0.6.1\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K  Attempting uninstall: pyarrow\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K    Found existing installation: pyarrow 21.0.0\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K    Uninstalling pyarrow-21.0.0:\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-21.0.0\u001b[0m \u001b[32m 40/209\u001b[0m [pyasn1]\n",
      "\u001b[2K  Attempting uninstall: psutil[90m\u001b[0m \u001b[32m 41/209\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: psutil 7.1.3\u001b[0m \u001b[32m 41/209\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling psutil-7.1.3:\u001b[0m \u001b[32m 41/209\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.1.3\u001b[0m \u001b[32m 41/209\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: protobuf90m\u001b[0m \u001b[32m 42/209\u001b[0m [psutil]\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.1\u001b[0m \u001b[32m 42/209\u001b[0m [psutil]\n",
      "\u001b[2K    Uninstalling protobuf-6.31.1:\u001b[0m \u001b[32m 42/209\u001b[0m [psutil]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.1\u001b[0m \u001b[32m 42/209\u001b[0m [psutil]\n",
      "\u001b[2K  Attempting uninstall: propcache0m\u001b[0m \u001b[32m 43/209\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: propcache 0.4.1\u001b[0m \u001b[32m 43/209\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling propcache-0.4.1:\u001b[0m \u001b[32m 43/209\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled propcache-0.4.1\u001b[0m \u001b[32m 43/209\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: prometheus_client\u001b[0m \u001b[32m 44/209\u001b[0m [propcache]\n",
      "\u001b[2K    Found existing installation: prometheus_client 0.23.1\u001b[0m \u001b[32m 44/209\u001b[0m [propcache]\n",
      "\u001b[2K    Uninstalling prometheus_client-0.23.1:\u001b[0m \u001b[32m 44/209\u001b[0m [propcache]\n",
      "\u001b[2K      Successfully uninstalled prometheus_client-0.23.1\u001b[0m \u001b[32m 44/209\u001b[0m [propcache]\n",
      "\u001b[2K  Attempting uninstall: pluggy\u001b[90m\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Found existing installation: pluggy 1.6.0\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Uninstalling pluggy-1.6.0:m\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K      Successfully uninstalled pluggy-1.6.0\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K  Attempting uninstall: platformdirs\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Found existing installation: platformdirs 4.5.0\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Uninstalling platformdirs-4.5.0:\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K      Successfully uninstalled platformdirs-4.5.0\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K  Attempting uninstall: pillowm\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Found existing installation: pillow 12.0.0\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K    Uninstalling pillow-12.0.0:\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.0.0\u001b[0m \u001b[32m 45/209\u001b[0m [prometheus_client]\n",
      "\u001b[2K  Attempting uninstall: pathspec[90m\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]client]\n",
      "\u001b[2K    Found existing installation: pathspec 0.12.1\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling pathspec-0.12.1:\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled pathspec-0.12.1\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: packaging\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 25.0\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: orjson0m\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: orjson 3.11.4\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling orjson-3.11.4:m\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled orjson-3.11.4\u001b[0m \u001b[32m 48/209\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: oauthlib[90m\u001b[0m \u001b[32m 51/209\u001b[0m [orjson]\n",
      "\u001b[2K    Found existing installation: oauthlib 3.3.1\u001b[0m \u001b[32m 51/209\u001b[0m [orjson]\n",
      "\u001b[2K    Uninstalling oauthlib-3.3.1:\u001b[0m \u001b[32m 51/209\u001b[0m [orjson]\n",
      "\u001b[2K      Successfully uninstalled oauthlib-3.3.1\u001b[0m \u001b[32m 51/209\u001b[0m [orjson]\n",
      "\u001b[2K  Attempting uninstall: numpy90m\u001b[0m \u001b[32m 51/209\u001b[0m [orjson]\n",
      "\u001b[2K    Found existing installation: numpy 2.1.3\u001b[0m \u001b[32m 51/209\u001b[0m [orjson]\n",
      "\u001b[2K    Uninstalling numpy-2.1.3:[0m\u001b[90m\u001b[0m \u001b[32m 53/209\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.1.3\u001b[0m \u001b[32m 53/209\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: networkx\u001b[90m\u001b[0m \u001b[32m 53/209\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: networkx 3.4.2\u001b[0m \u001b[32m 53/209\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.4.2:m\u001b[0m \u001b[32m 53/209\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.4.2\u001b[0m \u001b[32m 53/209\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: mypy_extensions\u001b[0m \u001b[32m 54/209\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: mypy_extensions 1.1.0\u001b[0m \u001b[32m 54/209\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling mypy_extensions-1.1.0:\u001b[0m \u001b[32m 55/209\u001b[0m [mypy_extensions]\n",
      "\u001b[2K      Successfully uninstalled mypy_extensions-1.1.0\u001b[0m \u001b[32m 55/209\u001b[0m [mypy_extensions]\n",
      "\u001b[2K  Attempting uninstall: mmh3\u001b[90m\u001b[0m \u001b[32m 55/209\u001b[0m [mypy_extensions]\n",
      "\u001b[2K    Found existing installation: mmh3 5.2.0\u001b[0m \u001b[32m 55/209\u001b[0m [mypy_extensions]\n",
      "\u001b[2K    Uninstalling mmh3-5.2.0:\u001b[90m\u001b[0m \u001b[32m 55/209\u001b[0m [mypy_extensions]\n",
      "\u001b[2K      Successfully uninstalled mmh3-5.2.0\u001b[0m \u001b[32m 56/209\u001b[0m [mmh3]nsions]\n",
      "\u001b[2K  Attempting uninstall: mdurl[90m\u001b[0m \u001b[32m 56/209\u001b[0m [mmh3]\n",
      "\u001b[2K    Found existing installation: mdurl 0.1.2\u001b[0m \u001b[32m 56/209\u001b[0m [mmh3]\n",
      "\u001b[2K    Uninstalling mdurl-0.1.2:[90m\u001b[0m \u001b[32m 56/209\u001b[0m [mmh3]\n",
      "\u001b[2K      Successfully uninstalled mdurl-0.1.2\u001b[0m \u001b[32m 56/209\u001b[0m [mmh3]\n",
      "\u001b[2K  Attempting uninstall: markupsafe90m\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.3\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.3:\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.3\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: locket90m\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Found existing installation: locket 1.0.0\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling locket-1.0.0:90m\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled locket-1.0.0\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: kiwisolver\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Found existing installation: kiwisolver 1.4.9\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling kiwisolver-1.4.9:\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled kiwisolver-1.4.9\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: joblib90m\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Found existing installation: joblib 1.5.2\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K    Uninstalling joblib-1.5.2:90m\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K      Successfully uninstalled joblib-1.5.2\u001b[0m \u001b[32m 57/209\u001b[0m [mdurl]\n",
      "\u001b[2K  Attempting uninstall: itsdangerous0m\u001b[0m \u001b[32m 61/209\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: itsdangerous 2.2.0\u001b[0m \u001b[32m 61/209\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling itsdangerous-2.2.0:\u001b[0m \u001b[32m 61/209\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled itsdangerous-2.2.0\u001b[0m \u001b[32m 61/209\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: iniconfig\u001b[90m\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K    Found existing installation: iniconfig 2.3.0\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K    Uninstalling iniconfig-2.3.0:m\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K      Successfully uninstalled iniconfig-2.3.0\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K  Attempting uninstall: idnam\u001b[90m\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K    Found existing installation: idna 3.11\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K    Uninstalling idna-3.11:0m\u001b[90m\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K  Attempting uninstall: httptoolsm\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K    Found existing installation: httptools 0.7.1\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K    Uninstalling httptools-0.7.1:m\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K      Successfully uninstalled httptools-0.7.1\u001b[0m \u001b[32m 62/209\u001b[0m [itsdangerous]\n",
      "\u001b[2K  Attempting uninstall: h110m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K    Found existing installation: h11 0.16.0\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K    Uninstalling h11-0.16.0:0m\u001b[90m\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K      Successfully uninstalled h11-0.16.0\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K  Attempting uninstall: greenlet90m\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K    Found existing installation: greenlet 3.2.4\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K    Uninstalling greenlet-3.2.4:90m\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K      Successfully uninstalled greenlet-3.2.4\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K  Attempting uninstall: graphql-core\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K    Found existing installation: graphql-core 3.2.7\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K    Uninstalling graphql-core-3.2.7:\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K      Successfully uninstalled graphql-core-3.2.7\u001b[0m \u001b[32m 65/209\u001b[0m [httptools]\n",
      "\u001b[2K  Attempting uninstall: google-crc32c90m\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K    Found existing installation: google-crc32c 1.7.1\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K    Uninstalling google-crc32c-1.7.1:\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K      Successfully uninstalled google-crc32c-1.7.1\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K  Attempting uninstall: fsspecm\u001b[90m\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.10.0\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K    Uninstalling fsspec-2025.10.0:0m\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.10.0\u001b[0m \u001b[32m 68/209\u001b[0m [graphql-core]\n",
      "\u001b[2K  Attempting uninstall: frozenlistm\u001b[90m\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]e]\n",
      "\u001b[2K    Found existing installation: frozenlist 1.8.0\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling frozenlist-1.8.0:0m\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled frozenlist-1.8.0\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: fonttools90m\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: fonttools 4.60.1\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling fonttools-4.60.1:0m\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled fonttools-4.60.1\u001b[0m \u001b[32m 70/209\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: filelock[0m\u001b[90m\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K    Found existing installation: filelock 3.20.0\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K    Uninstalling filelock-3.20.0:90m\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.20.0\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K  Attempting uninstall: entrypointsm\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K    Found existing installation: entrypoints 0.4\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K    Uninstalling entrypoints-0.4:90m\u001b[0m \u001b[32m 72/209\u001b[0m [fonttools]\n",
      "\u001b[2K      Successfully uninstalled entrypoints-0.4\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K  Attempting uninstall: dvc-render90m\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K    Found existing installation: dvc-render 1.0.2\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K    Uninstalling dvc-render-1.0.2:90m\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K      Successfully uninstalled dvc-render-1.0.2\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K  Attempting uninstall: dpath[0m\u001b[90m\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K    Found existing installation: dpath 2.2.0\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K    Uninstalling dpath-2.2.0:[0m\u001b[90m\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K      Successfully uninstalled dpath-2.2.0\u001b[0m \u001b[32m 74/209\u001b[0m [entrypoints]\n",
      "\u001b[2K  Attempting uninstall: docstring_parserm\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]s]\n",
      "\u001b[2K    Found existing installation: docstring_parser 0.17.0\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Uninstalling docstring_parser-0.17.0:\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K      Successfully uninstalled docstring_parser-0.17.0\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K  Attempting uninstall: distro0m\u001b[90m\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Found existing installation: distro 1.9.0\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Uninstalling distro-1.9.0:0m\u001b[90m\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K      Successfully uninstalled distro-1.9.0\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K  Attempting uninstall: diskcache[90m\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Found existing installation: diskcache 5.6.3\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Uninstalling diskcache-5.6.3:[90m\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K      Successfully uninstalled diskcache-5.6.3\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[0m\u001b[90m\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Found existing installation: dill 0.3.9\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K    Uninstalling dill-0.3.9:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K      Successfully uninstalled dill-0.3.9\u001b[0m \u001b[32m 76/209\u001b[0m [dpath]\n",
      "\u001b[2K  Attempting uninstall: decorator\u001b[0m\u001b[90m\u001b[0m \u001b[32m 80/209\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: decorator 5.2.1\u001b[0m \u001b[32m 80/209\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling decorator-5.2.1:\u001b[90m\u001b[0m \u001b[32m 80/209\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled decorator-5.2.1\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K  Attempting uninstall: cycler[0m\u001b[90m\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K    Found existing installation: cycler 0.12.1\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K    Uninstalling cycler-0.12.1:0m\u001b[90m\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K      Successfully uninstalled cycler-0.12.1\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K  Attempting uninstall: configobj\u001b[90m\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K    Found existing installation: configobj 5.0.9\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K    Uninstalling configobj-5.0.9:\u001b[90m\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K      Successfully uninstalled configobj-5.0.9\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K  Attempting uninstall: coloramam\u001b[90m\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K    Found existing installation: colorama 0.4.6\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K    Uninstalling colorama-0.4.6:m\u001b[90m\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K      Successfully uninstalled colorama-0.4.6\u001b[0m \u001b[32m 81/209\u001b[0m [decorator]\n",
      "\u001b[2K  Attempting uninstall: cloudpickle[0m\u001b[90m\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K    Found existing installation: cloudpickle 3.1.2\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K    Uninstalling cloudpickle-3.1.2:[90m\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K      Successfully uninstalled cloudpickle-3.1.2\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K  Attempting uninstall: click\u001b[0m\u001b[90m\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K    Found existing installation: click 8.1.8\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K    Uninstalling click-8.1.8:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K      Successfully uninstalled click-8.1.8\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.4\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.4:\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4\u001b[0m \u001b[32m 84/209\u001b[0m [colorama]\n",
      "\u001b[2K  Attempting uninstall: certifi1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: certifi 2025.10.5\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.10.5:[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.10.5\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: cachetools\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: cachetools 6.2.1\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling cachetools-6.2.1:\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled cachetools-6.2.1\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: blinker[0m\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: blinker 1.9.0\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling blinker-1.9.0:[0m\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled blinker-1.9.0\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: billiard0m\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: billiard 4.2.2\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling billiard-4.2.2:0m\u001b[90m\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled billiard-4.2.2\u001b[0m \u001b[32m 87/209\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: bigtree90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]lizer]\n",
      "\u001b[2K    Found existing installation: bigtree 1.0.3\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K    Uninstalling bigtree-1.0.3:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K      Successfully uninstalled bigtree-1.0.3\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K  Attempting uninstall: attrsm\u001b[0m\u001b[90m\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K    Found existing installation: attrs 25.4.0\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K    Uninstalling attrs-25.4.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.4.0\u001b[0m \u001b[32m 91/209\u001b[0m [billiard]\n",
      "\u001b[2K  Attempting uninstall: atpublic1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: atpublic 5.1\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling atpublic-5.1:\u001b[0m\u001b[90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled atpublic-5.1\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: async-timeout90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: async-timeout 5.0.1\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling async-timeout-5.0.1:90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled async-timeout-5.0.1\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: annotated-typesm\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: annotated-types 0.7.0\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling annotated-types-0.7.0:m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled annotated-types-0.7.0\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: annotated-doc90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: annotated-doc 0.0.3\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling annotated-doc-0.0.3:90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled annotated-doc-0.0.3\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: aiohappyeyeballs\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: aiohappyeyeballs 2.6.1\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling aiohappyeyeballs-2.6.1:\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.6.1\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: zc.lockfile\u001b[90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: zc.lockfile 4.0\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling zc.lockfile-4.0:0m\u001b[90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled zc.lockfile-4.0\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: werkzeug[0m\u001b[90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Found existing installation: Werkzeug 3.1.3\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K    Uninstalling Werkzeug-3.1.3:[0m\u001b[90m\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K      Successfully uninstalled Werkzeug-3.1.3\u001b[0m \u001b[32m 93/209\u001b[0m [attrs]\n",
      "\u001b[2K  Attempting uninstall: uvicorn\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: uvicorn 0.34.0\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Uninstalling uvicorn-0.34.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled uvicorn-0.34.0\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K  Attempting uninstall: typing-inspectionm\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.2\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.2:m\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.2\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K  Attempting uninstall: typeguard\u001b[0m\u001b[90m\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: typeguard 4.4.4\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Uninstalling typeguard-4.4.4:\u001b[0m\u001b[90m\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K      Successfully uninstalled typeguard-4.4.4\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K  Attempting uninstall: sqltriem\u001b[0m\u001b[90m\u001b[0m \u001b[32m100/209\u001b[0m [werkzeug]\n",
      "\u001b[2K    Found existing installation: sqltrie 0.11.2\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K    Uninstalling sqltrie-0.11.2:\u001b[0m\u001b[90m\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K      Successfully uninstalled sqltrie-0.11.2\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K  Attempting uninstall: sqlalchemy[0m\u001b[90m\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K    Found existing installation: SQLAlchemy 2.0.44\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K    Uninstalling SQLAlchemy-2.0.44:0m\u001b[90m\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K      Successfully uninstalled SQLAlchemy-2.0.44\u001b[0m \u001b[32m104/209\u001b[0m [sqltrie]\n",
      "\u001b[2K  Attempting uninstall: shapelym\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m105/209\u001b[0m [sqlalchemy]\n",
      "\u001b[2K    Found existing installation: shapely 2.1.2\u001b[0m \u001b[32m105/209\u001b[0m [sqlalchemy]\n",
      "\u001b[2K    Uninstalling shapely-2.1.2:0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m105/209\u001b[0m [sqlalchemy]\n",
      "\u001b[2K      Successfully uninstalled shapely-2.1.2\u001b[0m \u001b[32m105/209\u001b[0m [sqlalchemy]\n",
      "\u001b[2K  Attempting uninstall: scipy[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m106/209\u001b[0m [shapely]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.0\u001b[0m \u001b[32m106/209\u001b[0m [shapely]\n",
      "\u001b[2K    Uninstalling scipy-1.15.0:0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m107/209\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.0\u001b[0m \u001b[32m107/209\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: ruamel.yaml0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m107/209\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: ruamel.yaml 0.18.16\u001b[0m \u001b[32m107/209\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling ruamel.yaml-0.18.16:m\u001b[90m\u001b[0m \u001b[32m107/209\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled ruamel.yaml-0.18.16\u001b[0m \u001b[32m107/209\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: rsa\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Found existing installation: rsa 4.9.1m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Uninstalling rsa-4.9.1:m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K      Successfully uninstalled rsa-4.9.190m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K  Attempting uninstall: requestsm\u001b[0m\u001b[90m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:\u001b[0m\u001b[90m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.5\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K  Attempting uninstall: referencing[0m\u001b[90m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Found existing installation: referencing 0.37.0\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K    Uninstalling referencing-0.37.0:0m\u001b[90m\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K      Successfully uninstalled referencing-0.37.0\u001b[0m \u001b[32m108/209\u001b[0m [ruamel.yaml]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil\u001b[0m\u001b[90m\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K  Attempting uninstall: pydot\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K    Found existing installation: pydot 4.0.1\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K    Uninstalling pydot-4.0.1:\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K      Successfully uninstalled pydot-4.0.10m\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core0m\u001b[90m\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.27.2\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.27.2:m\u001b[90m\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.27.2\u001b[0m \u001b[32m111/209\u001b[0m [referencing]\n",
      "\u001b[2K  Attempting uninstall: pyasn1-modules\u001b[0m\u001b[90m\u001b[0m \u001b[32m114/209\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: pyasn1_modules 0.4.2\u001b[0m \u001b[32m114/209\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling pyasn1_modules-0.4.2:m\u001b[90m\u001b[0m \u001b[32m114/209\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled pyasn1_modules-0.4.2\u001b[0m \u001b[32m114/209\u001b[0m [pydantic-core]\n",
      "\u001b[2K  Attempting uninstall: proto-plus\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Found existing installation: proto-plus 1.26.1\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling proto-plus-1.26.1:\u001b[0m\u001b[90m\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K      Successfully uninstalled proto-plus-1.26.1\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K  Attempting uninstall: prompt-toolkit0m\u001b[90m\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Found existing installation: prompt_toolkit 3.0.52\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K    Uninstalling prompt_toolkit-3.0.52:m\u001b[90m\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K      Successfully uninstalled prompt_toolkit-3.0.52\u001b[0m \u001b[32m115/209\u001b[0m [pyasn1-modules]\n",
      "\u001b[2K  Attempting uninstall: partd\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m117/209\u001b[0m [prompt-toolkit]\n",
      "\u001b[2K    Found existing installation: partd 1.4.2m\u001b[0m \u001b[32m117/209\u001b[0m [prompt-toolkit]\n",
      "\u001b[2K    Uninstalling partd-1.4.2:m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m117/209\u001b[0m [prompt-toolkit]\n",
      "\u001b[2K      Successfully uninstalled partd-1.4.290m\u001b[0m \u001b[32m117/209\u001b[0m [prompt-toolkit]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-protom\u001b[90m\u001b[0m \u001b[32m118/209\u001b[0m [partd]lkit]\n",
      "\u001b[2K    Found existing installation: opentelemetry-proto 1.38.0\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K    Uninstalling opentelemetry-proto-1.38.0:m\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-proto-1.38.0\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K  Attempting uninstall: omegaconf1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K    Found existing installation: omegaconf 2.3.0\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K    Uninstalling omegaconf-2.3.0:1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K      Successfully uninstalled omegaconf-2.3.0\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K  Attempting uninstall: mypy0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K    Found existing installation: mypy 1.18.2m\u001b[0m \u001b[32m118/209\u001b[0m [partd]\n",
      "\u001b[2K    Uninstalling mypy-1.18.2:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m121/209\u001b[0m [mypy]\n",
      "\u001b[2K      Successfully uninstalled mypy-1.18.2[0m\u001b[90m\u001b[0m \u001b[32m121/209\u001b[0m [mypy]\n",
      "\u001b[2K  Attempting uninstall: multidict0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m121/209\u001b[0m [mypy]\n",
      "\u001b[2K    Found existing installation: multidict 6.7.0\u001b[0m \u001b[32m121/209\u001b[0m [mypy]\n",
      "\u001b[2K    Uninstalling multidict-6.7.0:90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m121/209\u001b[0m [mypy]\n",
      "\u001b[2K      Successfully uninstalled multidict-6.7.0[90m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K  Attempting uninstall: markdown-it-py[0m\u001b[90m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K    Found existing installation: markdown-it-py 4.0.0\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K    Uninstalling markdown-it-py-4.0.0:[0m\u001b[90m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K      Successfully uninstalled markdown-it-py-4.0.0\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K  Attempting uninstall: Mako[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K    Found existing installation: Mako 1.3.100m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K    Uninstalling Mako-1.3.10:0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K      Successfully uninstalled Mako-1.3.10[90m\u001b[0m \u001b[32m122/209\u001b[0m [multidict]\n",
      "\u001b[2K  Attempting uninstall: Jinja2\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m124/209\u001b[0m [Mako]]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6m\u001b[0m \u001b[32m124/209\u001b[0m [Mako]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m124/209\u001b[0m [Mako]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.690m\u001b[0m \u001b[32m124/209\u001b[0m [Mako]\n",
      "\u001b[2K  Attempting uninstall: importlib_metadata[90m\u001b[0m \u001b[32m124/209\u001b[0m [Mako]\n",
      "\u001b[2K    Found existing installation: importlib_metadata 8.7.0\u001b[0m \u001b[32m124/209\u001b[0m [Mako]\n",
      "\u001b[2K    Uninstalling importlib_metadata-8.7.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K      Successfully uninstalled importlib_metadata-8.7.0\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K  Attempting uninstall: httpcore\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K    Found existing installation: httpcore 1.0.9\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K    Uninstalling httpcore-1.0.9:\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K      Successfully uninstalled httpcore-1.0.90m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K  Attempting uninstall: gunicorn\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K    Found existing installation: gunicorn 23.0.0\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K    Uninstalling gunicorn-23.0.0:[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K      Successfully uninstalled gunicorn-23.0.0m\u001b[0m \u001b[32m126/209\u001b[0m [importlib_metadata]\n",
      "\u001b[2K  Attempting uninstall: grpcio\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m128/209\u001b[0m [gunicorn]adata]\n",
      "\u001b[2K    Found existing installation: grpcio 1.76.0m\u001b[0m \u001b[32m128/209\u001b[0m [gunicorn]\n",
      "\u001b[2K    Uninstalling grpcio-1.76.0:m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m128/209\u001b[0m [gunicorn]\n",
      "\u001b[2K      Successfully uninstalled grpcio-1.76.090m\u001b[0m \u001b[32m128/209\u001b[0m [gunicorn]\n",
      "\u001b[2K  Attempting uninstall: graphql-relay[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K    Found existing installation: graphql-relay 3.2.0\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K    Uninstalling graphql-relay-3.2.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K      Successfully uninstalled graphql-relay-3.2.0\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K  Attempting uninstall: grandalf\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K    Found existing installation: grandalf 0.80m\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K    Uninstalling grandalf-0.8:0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K      Successfully uninstalled grandalf-0.8[90m\u001b[0m \u001b[32m129/209\u001b[0m [grpcio]\n",
      "\u001b[2K  Attempting uninstall: googleapis-common-protos[90m\u001b[0m \u001b[32m131/209\u001b[0m [grandalf]\n",
      "\u001b[2K    Found existing installation: googleapis-common-protos 1.72.00m \u001b[32m131/209\u001b[0m [grandalf]\n",
      "\u001b[2K    Uninstalling googleapis-common-protos-1.72.0:\u001b[0m \u001b[32m131/209\u001b[0m [grandalf]\n",
      "\u001b[2K      Successfully uninstalled googleapis-common-protos-1.72.0\u001b[0m \u001b[32m131/209\u001b[0m [grandalf]\n",
      "\u001b[2K  Attempting uninstall: google-resumable-mediam\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: google-resumable-media 2.7.2\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling google-resumable-media-2.7.2:0m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled google-resumable-media-2.7.2\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K  Attempting uninstall: gitdb\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: gitdb 4.0.1290m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling gitdb-4.0.12:[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled gitdb-4.0.12\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K  Attempting uninstall: flufl.lock[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: flufl.lock 8.2.0\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling flufl.lock-8.2.0:[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled flufl.lock-8.2.0m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K  Attempting uninstall: flatten_dict0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Found existing installation: flatten-dict 0.4.2\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K    Uninstalling flatten-dict-0.4.2:0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K      Successfully uninstalled flatten-dict-0.4.2\u001b[0m \u001b[32m132/209\u001b[0m [googleapis-common-protos]\n",
      "\u001b[2K  Attempting uninstall: exceptiongroup\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]-protos]\n",
      "\u001b[2K    Found existing installation: exceptiongroup 1.3.0\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K    Uninstalling exceptiongroup-1.3.0:m\u001b[0m\u001b[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K      Successfully uninstalled exceptiongroup-1.3.0\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K  Attempting uninstall: dvc-objects[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K    Found existing installation: dvc-objects 5.1.2\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K    Uninstalling dvc-objects-5.1.2:[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K      Successfully uninstalled dvc-objects-5.1.2m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K  Attempting uninstall: dulwich[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K    Found existing installation: dulwich 0.24.80m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K    Uninstalling dulwich-0.24.8:0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K      Successfully uninstalled dulwich-0.24.8[90m\u001b[0m \u001b[32m136/209\u001b[0m [flatten_dict]\n",
      "\u001b[2K  Attempting uninstall: contourpy\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m139/209\u001b[0m [dulwich]]\n",
      "\u001b[2K    Found existing installation: contourpy 1.3.2m\u001b[0m \u001b[32m139/209\u001b[0m [dulwich]\n",
      "\u001b[2K    Uninstalling contourpy-1.3.2:m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m139/209\u001b[0m [dulwich]\n",
      "\u001b[2K      Successfully uninstalled contourpy-1.3.290m\u001b[0m \u001b[32m139/209\u001b[0m [dulwich]\n",
      "\u001b[2K  Attempting uninstall: click-pluginsm\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m140/209\u001b[0m [contourpy]\n",
      "\u001b[2K    Found existing installation: click-plugins 1.1.1.2\u001b[0m \u001b[32m140/209\u001b[0m [contourpy]\n",
      "\u001b[2K    Uninstalling click-plugins-1.1.1.2:\u001b[0m\u001b[90m\u001b[0m \u001b[32m140/209\u001b[0m [contourpy]\n",
      "\u001b[2K      Successfully uninstalled click-plugins-1.1.1.2m\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K  Attempting uninstall: click-didyoumean\u001b[0m\u001b[90m\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K    Found existing installation: click-didyoumean 0.3.1\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K    Uninstalling click-didyoumean-0.3.1:\u001b[0m\u001b[90m\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K      Successfully uninstalled click-didyoumean-0.3.1\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K  Attempting uninstall: cffi\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K    Found existing installation: cffi 2.0.0m\u001b[90m\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K    Uninstalling cffi-2.0.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m141/209\u001b[0m [click-plugins]\n",
      "\u001b[2K      Successfully uninstalled cffi-2.0.090m\u001b[0m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]gins]\n",
      "\u001b[2K  Attempting uninstall: amqp\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K    Found existing installation: amqp 5.3.10m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling amqp-5.3.1:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K      Successfully uninstalled amqp-5.3.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: aiosignal0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K    Found existing installation: aiosignal 1.4.00m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K    Uninstalling aiosignal-1.4.0:0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K      Successfully uninstalled aiosignal-1.4.0[90m\u001b[0m \u001b[32m143/209\u001b[0m [cffi]\n",
      "\u001b[2K  Attempting uninstall: yarl\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K    Found existing installation: yarl 1.22.0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K    Uninstalling yarl-1.22.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K      Successfully uninstalled yarl-1.22.0[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K  Attempting uninstall: uvicorn-worker1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K    Found existing installation: uvicorn-worker 0.3.0\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K    Uninstalling uvicorn-worker-0.3.0:1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K      Successfully uninstalled uvicorn-worker-0.3.0\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K  Attempting uninstall: scikit-learn[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.7.2\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K    Uninstalling scikit-learn-1.7.2:[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m145/209\u001b[0m [aiosignal]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.7.2m\u001b[90m\u001b[0m \u001b[32m148/209\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: rich\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m148/209\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Found existing installation: rich 13.9.40m\u001b[90m\u001b[0m \u001b[32m148/209\u001b[0m [scikit-learn]\n",
      "\u001b[2K    Uninstalling rich-13.9.4:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m148/209\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled rich-13.9.4\u001b[0m\u001b[90m\u001b[0m \u001b[32m148/209\u001b[0m [scikit-learn]\n",
      "\u001b[2K  Attempting uninstall: requests-oauthlib[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m149/209\u001b[0m [rich]arn]\n",
      "\u001b[2K    Found existing installation: requests-oauthlib 2.0.0\u001b[0m \u001b[32m149/209\u001b[0m [rich]\n",
      "\u001b[2K    Uninstalling requests-oauthlib-2.0.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m149/209\u001b[0m [rich]\n",
      "\u001b[2K      Successfully uninstalled requests-oauthlib-2.0.0\u001b[0m \u001b[32m149/209\u001b[0m [rich]\n",
      "\u001b[2K  Attempting uninstall: pytest\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m149/209\u001b[0m [rich]\n",
      "\u001b[2K    Found existing installation: pytest 8.4.2m\u001b[90m\u001b[0m \u001b[32m149/209\u001b[0m [rich]\n",
      "\u001b[2K    Uninstalling pytest-8.4.2:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m149/209\u001b[0m [rich]\n",
      "\u001b[2K      Successfully uninstalled pytest-8.4.21m\u001b[0m\u001b[90m\u001b[0m \u001b[32m151/209\u001b[0m [pytest]\n",
      "\u001b[2K  Attempting uninstall: pygit2\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m151/209\u001b[0m [pytest]\n",
      "\u001b[2K    Found existing installation: pygit2 1.18.2\u001b[90m\u001b[0m \u001b[32m151/209\u001b[0m [pytest]\n",
      "\u001b[2K    Uninstalling pygit2-1.18.2:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m151/209\u001b[0m [pytest]\n",
      "\u001b[2K      Successfully uninstalled pygit2-1.18.20m\u001b[90m\u001b[0m \u001b[32m151/209\u001b[0m [pytest]\n",
      "\u001b[2K  Attempting uninstall: pydantic\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m152/209\u001b[0m [pygit2]\n",
      "\u001b[2K    Found existing installation: pydantic 2.10.6[90m\u001b[0m \u001b[32m152/209\u001b[0m [pygit2]\n",
      "\u001b[2K    Uninstalling pydantic-2.10.6:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m152/209\u001b[0m [pygit2]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.10.6m\u001b[90m\u001b[0m \u001b[32m152/209\u001b[0m [pygit2]\n",
      "\u001b[2K  Attempting uninstall: pandas\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m153/209\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.30m\u001b[90m\u001b[0m \u001b[32m153/209\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m154/209\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3\u001b[0m\u001b[90m\u001b[0m \u001b[32m154/209\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-api\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m154/209\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: opentelemetry-api 1.37.0\u001b[0m \u001b[32m154/209\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling opentelemetry-api-1.37.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m154/209\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-api-1.37.0\u001b[0m \u001b[32m154/209\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m155/209\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.00m\u001b[0m \u001b[32m155/209\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.0:0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m155/209\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.0[0m\u001b[90m\u001b[0m \u001b[32m156/209\u001b[0m [matplotlib]pi]\n",
      "\u001b[2K  Attempting uninstall: kombu\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m156/209\u001b[0m [matplotlib]\n",
      "\u001b[2K    Found existing installation: kombu 5.5.4[0m\u001b[90m\u001b[0m \u001b[32m156/209\u001b[0m [matplotlib]\n",
      "\u001b[2K    Uninstalling kombu-5.5.4:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m156/209\u001b[0m [matplotlib]\n",
      "\u001b[2K      Successfully uninstalled kombu-5.5.4\u001b[0m\u001b[90m\u001b[0m \u001b[32m156/209\u001b[0m [matplotlib]\n",
      "\u001b[2K  Attempting uninstall: jsonschema-specifications[0m\u001b[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]]\n",
      "\u001b[2K    Found existing installation: jsonschema-specifications 2025.9.1\u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K    Uninstalling jsonschema-specifications-2025.9.1:m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K      Successfully uninstalled jsonschema-specifications-2025.9.1m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K  Attempting uninstall: iterative-telemetry\u001b[0m\u001b[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K    Found existing installation: iterative-telemetry 0.0.10\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K    Uninstalling iterative-telemetry-0.0.10:\u001b[0m\u001b[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K      Successfully uninstalled iterative-telemetry-0.0.10\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K  Attempting uninstall: hydra-core\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K    Found existing installation: hydra-core 1.3.2[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K    Uninstalling hydra-core-1.3.2:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K      Successfully uninstalled hydra-core-1.3.2m\u001b[90m\u001b[0m \u001b[32m157/209\u001b[0m [kombu]\n",
      "\u001b[2K  Attempting uninstall: grpcio-status\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m160/209\u001b[0m [hydra-core]\n",
      "\u001b[2K    Found existing installation: grpcio-status 1.76.0\u001b[0m \u001b[32m160/209\u001b[0m [hydra-core]\n",
      "\u001b[2K    Uninstalling grpcio-status-1.76.0:\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m160/209\u001b[0m [hydra-core]\n",
      "\u001b[2K      Successfully uninstalled grpcio-status-1.76.00m\u001b[0m \u001b[32m160/209\u001b[0m [hydra-core]\n",
      "\u001b[2K  Attempting uninstall: graphene\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m160/209\u001b[0m [hydra-core]\n",
      "\u001b[2K    Found existing installation: graphene 3.4.3m\u001b[90m\u001b[0m \u001b[32m160/209\u001b[0m [hydra-core]\n",
      "\u001b[2K    Uninstalling graphene-3.4.3:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m162/209\u001b[0m [graphene]\n",
      "\u001b[2K      Successfully uninstalled graphene-3.4.3\u001b[0m\u001b[90m\u001b[0m \u001b[32m162/209\u001b[0m [graphene]\n",
      "\u001b[2K  Attempting uninstall: google-auth\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m162/209\u001b[0m [graphene]\n",
      "\u001b[2K    Found existing installation: google-auth 2.41.190m\u001b[0m \u001b[32m162/209\u001b[0m [graphene]\n",
      "\u001b[2K    Uninstalling google-auth-2.41.1:[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m162/209\u001b[0m [graphene]\n",
      "\u001b[2K      Successfully uninstalled google-auth-2.41.1\u001b[90m\u001b[0m \u001b[32m162/209\u001b[0m [graphene]\n",
      "\u001b[2K  Attempting uninstall: gitpython\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m163/209\u001b[0m [google-auth]\n",
      "\u001b[2K    Found existing installation: GitPython 3.1.45\u001b[90m\u001b[0m \u001b[32m163/209\u001b[0m [google-auth]\n",
      "\u001b[2K    Uninstalling GitPython-3.1.45:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m163/209\u001b[0m [google-auth]\n",
      "\u001b[2K      Successfully uninstalled GitPython-3.1.450m\u001b[90m\u001b[0m \u001b[32m163/209\u001b[0m [google-auth]\n",
      "\u001b[2K  Attempting uninstall: Flask\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K    Found existing installation: Flask 3.1.2\u001b[0m\u001b[90m\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K    Uninstalling Flask-3.1.2:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K      Successfully uninstalled Flask-3.1.20m\u001b[0m\u001b[90m\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K  Attempting uninstall: dvc-studio-client90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K    Found existing installation: dvc-studio-client 0.22.0\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K    Uninstalling dvc-studio-client-0.22.0:0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m164/209\u001b[0m [gitpython]\n",
      "\u001b[2K      Successfully uninstalled dvc-studio-client-0.22.090m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K  Attempting uninstall: dvc-data\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K    Found existing installation: dvc-data 3.16.12\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K    Uninstalling dvc-data-3.16.12:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K      Successfully uninstalled dvc-data-3.16.120m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K  Attempting uninstall: docker\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K    Found existing installation: docker 7.1.0\u001b[0m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K    Uninstalling docker-7.1.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K      Successfully uninstalled docker-7.1.0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m166/209\u001b[0m [dvc-studio-client]\n",
      "\u001b[2K  Attempting uninstall: dask\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m168/209\u001b[0m [docker]client]\n",
      "\u001b[2K    Found existing installation: dask 2025.11.0[0m\u001b[90m\u001b[0m \u001b[32m168/209\u001b[0m [docker]\n",
      "\u001b[2K    Uninstalling dask-2025.11.0:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m168/209\u001b[0m [docker]\n",
      "\u001b[2K      Successfully uninstalled dask-2025.11.0\u001b[0m\u001b[90m\u001b[0m \u001b[32m168/209\u001b[0m [docker]\n",
      "\u001b[2K  Attempting uninstall: cryptography\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m169/209\u001b[0m [dask]\n",
      "\u001b[2K    Found existing installation: cryptography 46.0.390m\u001b[0m \u001b[32m169/209\u001b[0m [dask]\n",
      "\u001b[2K    Uninstalling cryptography-46.0.3:[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m169/209\u001b[0m [dask]\n",
      "\u001b[2K      Successfully uninstalled cryptography-46.0.3\u001b[90m\u001b[0m \u001b[32m169/209\u001b[0m [dask]\n",
      "\u001b[2K  Attempting uninstall: click-repl\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m170/209\u001b[0m [cryptography]\n",
      "\u001b[2K    Found existing installation: click-repl 0.3.0m\u001b[90m\u001b[0m \u001b[32m170/209\u001b[0m [cryptography]\n",
      "\u001b[2K    Uninstalling click-repl-0.3.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m170/209\u001b[0m [cryptography]\n",
      "\u001b[2K      Successfully uninstalled click-repl-0.3.0[0m\u001b[90m\u001b[0m \u001b[32m170/209\u001b[0m [cryptography]\n",
      "\u001b[2K  Attempting uninstall: anyio\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K    Found existing installation: anyio 4.11.0\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K    Uninstalling anyio-4.11.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K      Successfully uninstalled anyio-4.11.01m\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K  Attempting uninstall: alembic\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K    Found existing installation: alembic 1.17.1[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K    Uninstalling alembic-1.17.1:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K      Successfully uninstalled alembic-1.17.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m171/209\u001b[0m [click-repl]\n",
      "\u001b[2K  Attempting uninstall: watchfiles\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m173/209\u001b[0m [alembic]\n",
      "\u001b[2K    Found existing installation: watchfiles 1.1.10m\u001b[90m\u001b[0m \u001b[32m173/209\u001b[0m [alembic]\n",
      "\u001b[2K    Uninstalling watchfiles-1.1.1:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K      Successfully uninstalled watchfiles-1.1.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K  Attempting uninstall: typer\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K    Found existing installation: typer 0.20.0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K    Uninstalling typer-0.20.0:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K      Successfully uninstalled typer-0.20.090m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K  Attempting uninstall: starlette\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K    Found existing installation: starlette 0.49.30m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K    Uninstalling starlette-0.49.3:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K      Successfully uninstalled starlette-0.49.3\u001b[0m\u001b[90m\u001b[0m \u001b[32m174/209\u001b[0m [watchfiles]\n",
      "\u001b[2K  Attempting uninstall: pydantic-settings\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m176/209\u001b[0m [starlette]\n",
      "\u001b[2K    Found existing installation: pydantic-settings 2.11.0\u001b[0m \u001b[32m176/209\u001b[0m [starlette]\n",
      "\u001b[2K    Uninstalling pydantic-settings-2.11.0:[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m176/209\u001b[0m [starlette]\n",
      "\u001b[2K      Successfully uninstalled pydantic-settings-2.11.0m\u001b[0m \u001b[32m176/209\u001b[0m [starlette]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions\u001b[0m \u001b[32m176/209\u001b[0m [starlette]\n",
      "\u001b[2K    Found existing installation: opentelemetry-semantic-conventions 0.58b06/209\u001b[0m [starlette]\n",
      "\u001b[2K    Uninstalling opentelemetry-semantic-conventions-0.58b0:\u001b[0m \u001b[32m176/209\u001b[0m [starlette]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0176/209\u001b[0m [starlette]\n",
      "\u001b[2K  Attempting uninstall: jsonschema\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Found existing installation: jsonschema 4.25.1\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Uninstalling jsonschema-4.25.1:\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K      Successfully uninstalled jsonschema-4.25.10m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K  Attempting uninstall: httpx\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Found existing installation: httpx 0.28.1\u001b[90m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.10m\u001b[90m\u001b[0m \u001b[32m178/209\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K  Attempting uninstall: grpc-google-iam-v1\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]ntic-conventions]\n",
      "\u001b[2K    Found existing installation: grpc-google-iam-v1 0.14.3\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K    Uninstalling grpc-google-iam-v1-0.14.3:[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K      Successfully uninstalled grpc-google-iam-v1-0.14.3m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K  Attempting uninstall: google-auth-oauthlib90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K    Found existing installation: google-auth-oauthlib 1.2.3\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K    Uninstalling google-auth-oauthlib-1.2.3:90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K      Successfully uninstalled google-auth-oauthlib-1.2.3\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K  Attempting uninstall: google-api-core[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K    Found existing installation: google-api-core 2.28.10m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K    Uninstalling google-api-core-2.28.1:0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K      Successfully uninstalled google-api-core-2.28.1[90m\u001b[0m \u001b[32m180/209\u001b[0m [httpx]\n",
      "\u001b[2K  Attempting uninstall: Flask-CORS\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K    Found existing installation: flask-cors 6.0.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K    Uninstalling flask-cors-6.0.1:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K      Successfully uninstalled flask-cors-6.0.1m\u001b[0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K  Attempting uninstall: databricks-sdk\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K    Found existing installation: databricks-sdk 0.73.0[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K    Uninstalling databricks-sdk-0.73.0:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K      Successfully uninstalled databricks-sdk-0.73.0m\u001b[90m\u001b[0m \u001b[32m183/209\u001b[0m [google-api-core]\n",
      "\u001b[2K  Attempting uninstall: celery\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m185/209\u001b[0m [databricks-sdk]\n",
      "\u001b[2K    Found existing installation: celery 5.5.390m\u001b[0m\u001b[90m\u001b[0m \u001b[32m185/209\u001b[0m [databricks-sdk]\n",
      "\u001b[2K    Uninstalling celery-5.5.3:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m185/209\u001b[0m [databricks-sdk]\n",
      "\u001b[2K      Successfully uninstalled celery-5.5.3\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m185/209\u001b[0m [databricks-sdk]\n",
      "\u001b[2K  Attempting uninstall: asyncssh\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m186/209\u001b[0m [celery]sdk]\n",
      "\u001b[2K    Found existing installation: asyncssh 2.21.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m186/209\u001b[0m [celery]\n",
      "\u001b[2K    Uninstalling asyncssh-2.21.1:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m187/209\u001b[0m [asyncssh]\n",
      "\u001b[2K      Successfully uninstalled asyncssh-2.21.11m\u001b[0m\u001b[90m\u001b[0m \u001b[32m187/209\u001b[0m [asyncssh]\n",
      "\u001b[2K  Attempting uninstall: aiohttp\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m187/209\u001b[0m [asyncssh]\n",
      "\u001b[2K    Found existing installation: aiohttp 3.13.2m\u001b[0m\u001b[90m\u001b[0m \u001b[32m187/209\u001b[0m [asyncssh]\n",
      "\u001b[2K    Uninstalling aiohttp-3.13.2:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m187/209\u001b[0m [asyncssh]\n",
      "\u001b[2K      Successfully uninstalled aiohttp-3.13.291m\u001b[0m\u001b[90m\u001b[0m \u001b[32m187/209\u001b[0m [asyncssh]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-sdk\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K    Found existing installation: opentelemetry-sdk 1.37.0m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling opentelemetry-sdk-1.37.0:m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-sdk-1.37.090m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K  Attempting uninstall: google-genai\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K    Found existing installation: google-genai 1.49.0m\u001b[90m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling google-genai-1.49.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K      Successfully uninstalled google-genai-1.49.0[0m\u001b[90m\u001b[0m \u001b[32m188/209\u001b[0m [aiohttp]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-core\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K    Found existing installation: google-cloud-core 2.5.090m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K    Uninstalling google-cloud-core-2.5.0:[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-core-2.5.0\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K  Attempting uninstall: fastapi\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K    Found existing installation: fastapi 0.121.0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K    Uninstalling fastapi-0.121.0:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K      Successfully uninstalled fastapi-0.121.090m\u001b[0m\u001b[90m\u001b[0m \u001b[32m190/209\u001b[0m [google-genai]\n",
      "\u001b[2K  Attempting uninstall: dvc-task\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]]\n",
      "\u001b[2K    Found existing installation: dvc-task 0.40.2m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K    Uninstalling dvc-task-0.40.2:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K      Successfully uninstalled dvc-task-0.40.291m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K  Attempting uninstall: aiohttp-retry\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K    Found existing installation: aiohttp-retry 2.9.10m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K    Uninstalling aiohttp-retry-2.9.1:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K      Successfully uninstalled aiohttp-retry-2.9.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K  Attempting uninstall: scmrepo\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K    Found existing installation: scmrepo 3.5.291m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K    Uninstalling scmrepo-3.5.2:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K      Successfully uninstalled scmrepo-3.5.2\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m192/209\u001b[0m [fastapi]\n",
      "\u001b[2K  Attempting uninstall: mlflow-tracing\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m195/209\u001b[0m [scmrepo]\n",
      "\u001b[2K    Found existing installation: mlflow-tracing 3.5.10m\u001b[90m\u001b[0m \u001b[32m195/209\u001b[0m [scmrepo]\n",
      "\u001b[2K    Uninstalling mlflow-tracing-3.5.1:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m195/209\u001b[0m [scmrepo]\n",
      "\u001b[2K      Successfully uninstalled mlflow-tracing-3.5.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m195/209\u001b[0m [scmrepo]\n",
      "\u001b[2K  Attempting uninstall: mlflow-skinny\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m196/209\u001b[0m [mlflow-tracing]\n",
      "\u001b[2K    Found existing installation: mlflow-skinny 3.5.1[0m\u001b[90m\u001b[0m \u001b[32m196/209\u001b[0m [mlflow-tracing]\n",
      "\u001b[2K    Uninstalling mlflow-skinny-3.5.1:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m197/209\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K      Successfully uninstalled mlflow-skinny-3.5.1\u001b[0m\u001b[90m\u001b[0m \u001b[32m197/209\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-storage\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m197/209\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K    Found existing installation: google-cloud-storage 3.5.0m\u001b[0m \u001b[32m197/209\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K    Uninstalling google-cloud-storage-3.5.0:m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m197/209\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-storage-3.5.090m\u001b[0m \u001b[32m197/209\u001b[0m [mlflow-skinny]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-resource-managerm\u001b[0m\u001b[90m\u001b[0m \u001b[32m198/209\u001b[0m [google-cloud-storage]\n",
      "\u001b[2K    Found existing installation: google-cloud-resource-manager 1.15.032m198/209\u001b[0m [google-cloud-storage]\n",
      "\u001b[2K    Uninstalling google-cloud-resource-manager-1.15.0:m\u001b[90m\u001b[0m \u001b[32m198/209\u001b[0m [google-cloud-storage]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-resource-manager-1.15.0\u001b[32m198/209\u001b[0m [google-cloud-storage]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-bigquery0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m199/209\u001b[0m [google-cloud-resource-manager]\n",
      "\u001b[2K    Found existing installation: google-cloud-bigquery 3.38.00m \u001b[32m199/209\u001b[0m [google-cloud-resource-manager]\n",
      "\u001b[2K    Uninstalling google-cloud-bigquery-3.38.0:0m\u001b[0m\u001b[90m\u001b[0m \u001b[32m199/209\u001b[0m [google-cloud-resource-manager]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-bigquery-3.38.0\u001b[0m \u001b[32m199/209\u001b[0m [google-cloud-resource-manager]\n",
      "\u001b[2K  Attempting uninstall: feast\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m200/209\u001b[0m [google-cloud-bigquery]]\n",
      "\u001b[2K    Found existing installation: feast 0.56.0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m200/209\u001b[0m [google-cloud-bigquery]\n",
      "\u001b[2K    Uninstalling feast-0.56.0:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]ud-bigquery]\n",
      "\u001b[2K      Successfully uninstalled feast-0.56.0[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K  Attempting uninstall: dvc-http\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K    Found existing installation: dvc-http 2.32.090m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K    Uninstalling dvc-http-2.32.0:\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K      Successfully uninstalled dvc-http-2.32.0\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K  Attempting uninstall: mlflow\u001b[0m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K    Found existing installation: mlflow 3.5.1m\u001b[90m\u001b[0m\u001b[90m\u001b[0m \u001b[32m201/209\u001b[0m [feast]\n",
      "\u001b[2K    Uninstalling mlflow-3.5.1:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K      Successfully uninstalled mlflow-3.5.1[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K  Attempting uninstall: gto\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K    Found existing installation: gto 1.9.0\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K    Uninstalling gto-1.9.0:\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K      Successfully uninstalled gto-1.9.0\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-aiplatform[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K    Found existing installation: google-cloud-aiplatform 1.126.00m \u001b[32m203/209\u001b[0m [mlflow]\n",
      "\u001b[2K    Uninstalling google-cloud-aiplatform-1.126.0:0m\u001b[90m\u001b[0m \u001b[32m205/209\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-aiplatform-1.126.0\u001b[32m205/209\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K  Attempting uninstall: gcsfs\u001b[0m\u001b[90m\u001b[0m \u001b[32m205/209\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K    Found existing installation: gcsfs 2025.10.0[90m\u001b[0m \u001b[32m205/209\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K    Uninstalling gcsfs-2025.10.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m205/209\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K      Successfully uninstalled gcsfs-2025.10.0m\u001b[90m\u001b[0m \u001b[32m205/209\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K  Attempting uninstall: dvc\u001b[0m\u001b[90m\u001b[0m \u001b[32m206/209\u001b[0m [gcsfs]ud-aiplatform]\n",
      "\u001b[2K    Found existing installation: dvc 3.63.0\u001b[0m\u001b[90m\u001b[0m \u001b[32m206/209\u001b[0m [gcsfs]\n",
      "\u001b[2K    Uninstalling dvc-3.63.0:\u001b[0m\u001b[90m\u001b[0m \u001b[32m206/209\u001b[0m [gcsfs]\n",
      "\u001b[2K      Successfully uninstalled dvc-3.63.0\u001b[0m\u001b[90m\u001b[0m \u001b[32m206/209\u001b[0m [gcsfs]\n",
      "\u001b[2K  Attempting uninstall: dvc-gs\u001b[0m\u001b[91m\u001b[0m \u001b[32m207/209\u001b[0m [dvc]\n",
      "\u001b[2K    Found existing installation: dvc-gs 3.0.20m\u001b[91m\u001b[0m \u001b[32m207/209\u001b[0m [dvc]\n",
      "\u001b[2K    Uninstalling dvc-gs-3.0.2:\u001b[0m\u001b[91m\u001b[0m \u001b[32m207/209\u001b[0m [dvc]\n",
      "\u001b[2K      Successfully uninstalled dvc-gs-3.0.2\u001b[0m\u001b[91m\u001b[0m \u001b[32m207/209\u001b[0m [dvc]\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m209/209\u001b[0m [dvc-gs]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.1 Jinja2-3.1.6 Mako-1.3.10 PyYAML-6.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiohttp-retry-2.9.1 aiosignal-1.4.0 alembic-1.17.1 amqp-5.3.1 annotated-doc-0.0.3 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.11.0 appdirs-1.4.4 async-timeout-5.0.1 asyncssh-2.21.1 atpublic-5.1 attrs-25.4.0 bigtree-1.0.3 billiard-4.2.2 blinker-1.9.0 cachetools-6.2.1 celery-5.5.3 certifi-2025.10.5 cffi-2.0.0 charset_normalizer-3.4.4 click-8.1.8 click-didyoumean-0.3.1 click-plugins-1.1.1.2 click-repl-0.3.0 cloudpickle-3.1.2 colorama-0.4.6 configobj-5.0.9 contourpy-1.3.2 cryptography-46.0.3 cycler-0.12.1 dask-2025.11.0 databricks-sdk-0.73.0 decorator-5.2.1 dictdiffer-0.9.0 dill-0.3.9 diskcache-5.6.3 distro-1.9.0 docker-7.1.0 docstring_parser-0.17.0 dpath-2.2.0 dulwich-0.24.8 dvc-3.63.0 dvc-data-3.16.12 dvc-gs-3.0.2 dvc-http-2.32.0 dvc-objects-5.1.2 dvc-render-1.0.2 dvc-studio-client-0.22.0 dvc-task-0.40.2 entrypoints-0.4 exceptiongroup-1.3.0 fastapi-0.121.0 feast-0.56.0 filelock-3.20.0 flatten_dict-0.4.2 flufl.lock-8.2.0 fonttools-4.60.1 frozenlist-1.8.0 fsspec-2025.10.0 funcy-2.0 gcsfs-2025.10.0 gitdb-4.0.12 gitpython-3.1.45 google-api-core-2.28.1 google-auth-2.41.1 google-auth-oauthlib-1.2.3 google-cloud-aiplatform-1.126.0 google-cloud-bigquery-3.38.0 google-cloud-core-2.5.0 google-cloud-resource-manager-1.15.0 google-cloud-storage-3.5.0 google-crc32c-1.7.1 google-genai-1.49.0 google-resumable-media-2.7.2 googleapis-common-protos-1.72.0 grandalf-0.8 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.2.4 grpc-google-iam-v1-0.14.3 grpcio-1.76.0 grpcio-status-1.76.0 gto-1.9.0 gunicorn-23.0.0 h11-0.16.0 httpcore-1.0.9 httptools-0.7.1 httpx-0.28.1 hydra-core-1.3.2 idna-3.11 importlib_metadata-8.7.0 iniconfig-2.3.0 iterative-telemetry-0.0.10 itsdangerous-2.2.0 joblib-1.5.2 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 kombu-5.5.4 locket-1.0.0 markdown-it-py-4.0.0 markupsafe-3.0.3 matplotlib-3.10.0 mdurl-0.1.2 mlflow-3.5.1 mlflow-skinny-3.5.1 mlflow-tracing-3.5.1 mmh3-5.2.0 multidict-6.7.0 mypy-1.18.2 mypy_extensions-1.1.0 networkx-3.4.2 numpy-2.1.3 oauthlib-3.3.1 omegaconf-2.3.0 opentelemetry-api-1.37.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 orjson-3.11.4 packaging-25.0 pandas-2.3.3 partd-1.4.2 pathspec-0.12.1 pillow-12.0.0 platformdirs-4.5.0 pluggy-1.6.0 prometheus_client-0.23.1 prompt-toolkit-3.0.52 propcache-0.4.1 proto-plus-1.26.1 protobuf-6.31.1 psutil-7.1.3 pyarrow-21.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.11.0 pydot-4.0.1 pygit2-1.18.2 pygments-2.19.2 pygtrie-2.5.0 pyjwt-2.10.1 pyparsing-3.2.5 pytest-8.4.2 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 referencing-0.37.0 requests-2.32.5 requests-oauthlib-2.0.0 rich-13.9.4 rpds-py-0.28.0 rsa-4.9.1 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 scikit-learn-1.7.2 scipy-1.15.0 scmrepo-3.5.2 semver-3.0.4 setuptools-80.9.0 shapely-2.1.2 shellingham-1.5.4 shortuuid-1.0.13 shtab-1.7.2 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.44 sqlparse-0.5.3 sqltrie-0.11.2 starlette-0.49.3 tabulate-0.9.0 tenacity-8.5.0 threadpoolctl-3.6.0 toml-0.10.2 tomli-2.3.0 tomlkit-0.13.3 toolz-1.1.0 tqdm-4.67.1 typeguard-4.4.4 typer-0.20.0 typing-inspection-0.4.2 typing_extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.34.0 uvicorn-worker-0.3.0 uvloop-0.22.1 vine-5.1.0 voluptuous-0.15.2 watchfiles-1.1.1 wcwidth-0.2.14 websockets-15.0.1 werkzeug-3.1.3 yarl-1.22.0 zc.lockfile-4.0 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --force-reinstall -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GCS Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://iitmbs-mlops-21f1000344\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3938f6d37a1"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e95ca1e5e07c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from feast import FeatureStore, Entity, FeatureView, Field, FileSource\n",
    "from feast.types import Float64, Int64\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Git Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
      "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
      "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
      "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
      "\u001b[33mhint: \u001b[m\n",
      "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
      "Initialized empty Git repository in /home/jupyter/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"chandrakarsatvik@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global user.name \"Satvik Chandrakar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.dvc/\u001b[m\n",
      "\t\u001b[31m.dvcignore\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.github/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31mfeature_repo/\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\t\u001b[31mrequirements.txt\u001b[m\n",
      "\t\u001b[31msrc/\u001b[m\n",
      "\t\u001b[31mtests/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Actions for CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Required Secrets Keys\n",
    "- GCP_KEY_JSON\n",
    "- GCP_KEY_BASE64\n",
    "- MLFLOW_TRACKING_URI\n",
    "- MLFLOW_EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert key to Base64\n",
    "!base64 -w 0 iitmbs-mlops-a99d6ce657ac.json > gcp-key.b64.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory .github/: File exists\n",
      "mkdir: cannot create directory .github/workflows/: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir .github/\n",
    "mkdir .github/workflows/\n",
    "touch .github/workflows/ci-dev.yml\n",
    "cat > .github/workflows/ci-dev.yml <<'EOF'\n",
    "name: CI - Dev Branch\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [dev]\n",
    "  pull_request:\n",
    "    branches: [dev, main]\n",
    "\n",
    "permissions:\n",
    "  contents: write\n",
    "  pull-requests: write\n",
    "\n",
    "jobs:\n",
    "  dev-ci:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout repository\n",
    "        uses: actions/checkout@v4\n",
    "        with:\n",
    "          fetch-depth: 0\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Configure DVC Remote\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GCP_KEY_JSON }}\n",
    "        run: |\n",
    "          echo \"${GOOGLE_APPLICATION_CREDENTIALS}\" > gcp-key.json\n",
    "          dvc remote modify myremote credentialpath gcp-key.json\n",
    "        \n",
    "      - name: Setup GCP credentials\n",
    "        run: |\n",
    "          echo \"${{ secrets.GCP_KEY_BASE64 }}\" | base64 --decode > gcp-key.json\n",
    "          echo \"GCP key file written to gcp-key.json\"\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: gcp-key.json\n",
    "\n",
    "      - name: Pull data from DVC\n",
    "        run: dvc pull -r myremote\n",
    "\n",
    "      - name: Fetch best model from MLflow\n",
    "        env:\n",
    "          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}\n",
    "          MLFLOW_EXPERIMENT_NAME: ${{ secrets.MLFLOW_EXPERIMENT_NAME }}\n",
    "        run: |\n",
    "          echo \"Fetching best model from MLflow experiment...\"\n",
    "          python <<'PYCODE'\n",
    "          import mlflow\n",
    "          from mlflow.tracking import MlflowClient\n",
    "          import os, shutil\n",
    "\n",
    "          client = MlflowClient()\n",
    "          experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\")\n",
    "          experiment = client.get_experiment_by_name(experiment_name)\n",
    "          if not experiment:\n",
    "              raise SystemExit(f\"Experiment '{experiment_name}' not found in MLflow.\")\n",
    "          \n",
    "          experiment_id = experiment.experiment_id\n",
    "          print(f\"Searching best model from experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "\n",
    "          results = mlflow.search_logged_models(\n",
    "              experiment_ids=[experiment_id],\n",
    "              order_by=[{\"field_name\": \"metrics.accuracy\", \"ascending\": False}],\n",
    "              max_results=1,\n",
    "              output_format=\"list\"\n",
    "          )\n",
    "\n",
    "          if not results:\n",
    "              raise SystemExit(\"No logged models found in this experiment.\")\n",
    "\n",
    "          best_model = results[0]\n",
    "          print(f\"Best model ID: {best_model.model_id}\")\n",
    "          print(f\"Accuracy: {best_model.metrics[0].value}\")\n",
    "\n",
    "          model_uri = f\"models:/{best_model.model_id}\"\n",
    "          output_dir = \"fetched_model\"\n",
    "          if os.path.exists(output_dir):\n",
    "              shutil.rmtree(output_dir)\n",
    "\n",
    "          os.makedirs(output_dir, exist_ok=True)\n",
    "          mlflow.artifacts.download_artifacts(artifact_uri=model_uri, dst_path=output_dir)\n",
    "          print(f\"Saved best model locally at '{output_dir}/'\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Model sanity check & accuracy evaluation\n",
    "        run: |\n",
    "          python <<'PYCODE'\n",
    "          import mlflow.pyfunc\n",
    "          import pandas as pd\n",
    "          from sklearn.model_selection import train_test_split\n",
    "          from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "          model = mlflow.pyfunc.load_model(\"fetched_model\")\n",
    "          df = pd.read_parquet(\"data/stock_data.parquet\")\n",
    "\n",
    "          X = df[['open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14']]\n",
    "          y = df[\"target\"]\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "          y_pred = model.predict(X_test)\n",
    "          acc = accuracy_score(y_test, y_pred)\n",
    "          report = classification_report(y_test, y_pred, output_dict=False)\n",
    "\n",
    "          print(f\"Test Accuracy: {acc:.4f}\")\n",
    "          print(report)\n",
    "\n",
    "          with open(\"accuracy_report.md\", \"w\") as f:\n",
    "              f.write(\"## Model Evaluation Report\\n\\n\")\n",
    "              f.write(f\"**Test Accuracy:** {acc:.4f}\\n\\n\")\n",
    "              f.write(\"```text\\n\")\n",
    "              f.write(\"### Classification Report\\n\\n\")\n",
    "              f.write(report)\n",
    "              f.write(\"\\n```\\n\\n\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Run unit tests and generate Markdown report\n",
    "        run: |\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --junitxml=report.xml > pytest_output.txt\n",
    "\n",
    "          echo \"## Dev Branch Pytest Summary Report\" > dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          echo \"**Date:** $(date)\" >> dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          echo \"### Test Results:\" >> dev_report.md\n",
    "          echo '```' >> dev_report.md\n",
    "          cat pytest_output.txt >> dev_report.md\n",
    "          echo '```' >> dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --cov=. --cov-report=term-missing >> pytest_output.txt 2>&1 || true\n",
    "\n",
    "      - name: Sample Prediction (Feast Online Store)\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: gcp-key.json\n",
    "        run: |\n",
    "          python <<'PYCODE'\n",
    "          from feast import FeatureStore\n",
    "          import pandas as pd\n",
    "          import mlflow.pyfunc\n",
    "\n",
    "          # Load Feature Store\n",
    "          store = FeatureStore(repo_path=\"feature_repo\")\n",
    "\n",
    "          # Detect data version\n",
    "          df = pd.read_parquet(\"data/stock_data.parquet\")\n",
    "          if \"stock_v1_id\" in df.columns:\n",
    "              version = \"v1\"\n",
    "              id_col = \"stock_v1_id\"\n",
    "          elif \"stock_v2_id\" in df.columns:\n",
    "              version = \"v2\"\n",
    "              id_col = \"stock_v2_id\"\n",
    "          else:\n",
    "              raise ValueError(\"No version column found (expected stock_v1_id or stock_v2_id).\")\n",
    "\n",
    "          print(f\" Detected feature view version: {version}\")\n",
    "\n",
    "          # Load model\n",
    "          model = mlflow.pyfunc.load_model(\"fetched_model\")\n",
    "\n",
    "          sample_rows = []\n",
    "          sample_ids = df[id_col].unique()[:5]\n",
    "          for entity_id in sample_ids:\n",
    "              entity_df = pd.DataFrame({id_col: [entity_id]})\n",
    "\n",
    "              print(\"\\n===============================\")\n",
    "              print(\"Requesting online features for entities:\", entity_df.to_dict(orient='records'))\n",
    "\n",
    "              feature_vector = store.get_online_features(\n",
    "                  features=[\n",
    "                      f\"stock_features_{version}:open\",\n",
    "                      f\"stock_features_{version}:high\",\n",
    "                      f\"stock_features_{version}:low\",\n",
    "                      f\"stock_features_{version}:close\",\n",
    "                      f\"stock_features_{version}:volume\",\n",
    "                      f\"stock_features_{version}:ma_15_min\",\n",
    "                      f\"stock_features_{version}:ma_60_min\",\n",
    "                      f\"stock_features_{version}:rsi_14\",\n",
    "                  ],\n",
    "                  entity_rows=entity_df.to_dict(orient=\"records\"),\n",
    "              ).to_df()\n",
    "\n",
    "              print(\"Online features (raw):\")\n",
    "              print(feature_vector)\n",
    "\n",
    "              X = feature_vector.drop(columns=[id_col])\n",
    "              pred = model.predict(X)[0]\n",
    "\n",
    "              # Find true label from df (if available)\n",
    "              true_label = df.loc[df[id_col] == entity_id, \"target\"].values[0] if entity_id in df[id_col].values else \"N/A\"\n",
    "\n",
    "              print(f\"Predicted target: {pred}, True target: {true_label}\")\n",
    "              sample_rows.append({\"Entity\": entity_id, \"True\": true_label, \"Predicted\": pred})\n",
    "\n",
    "          # Append to Markdown report\n",
    "          if sample_rows:\n",
    "              sample_df = pd.DataFrame(sample_rows)\n",
    "              with open(\"accuracy_report.md\", \"a\") as f:\n",
    "                  f.write(\"### Sample Predictions (Feast Online Store)\\n\\n\")\n",
    "                  f.write(sample_df.to_markdown(index=False))\n",
    "                  f.write(\"\\n\\n\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Set up CML\n",
    "        uses: iterative/setup-cml@v2\n",
    "        with:\n",
    "          version: latest\n",
    "          vega: true\n",
    "        env:\n",
    "          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "\n",
    "      - name: Comment CML Report on commit (push)\n",
    "        if: github.event_name == 'push'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> dev_report.md\n",
    "          cml comment create --target=commit --publish dev_report.md\n",
    "\n",
    "      - name: Comment CML Report on PR (pull request)\n",
    "        if: github.event_name == 'pull_request'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> dev_report.md\n",
    "          cml comment create --target=pr --publish dev_report.md\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch .github/workflows/ci-main.yml\n",
    "cat > .github/workflows/ci-main.yml <<'EOF'\n",
    "name: CI - Main Branch\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "permissions:\n",
    "  contents: write\n",
    "  pull-requests: write\n",
    "\n",
    "jobs:\n",
    "  main-ci:\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "      - name: Checkout repository\n",
    "        uses: actions/checkout@v4\n",
    "        with:\n",
    "          fetch-depth: 0\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "\n",
    "      - name: Install dependencies\n",
    "        run: pip install -r requirements.txt\n",
    "\n",
    "      - name: Configure DVC Remote\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GCP_KEY_JSON }}\n",
    "        run: |\n",
    "          echo \"${GOOGLE_APPLICATION_CREDENTIALS}\" > gcp-key.json\n",
    "          dvc remote modify myremote credentialpath gcp-key.json\n",
    "        \n",
    "      - name: Setup GCP credentials\n",
    "        run: |\n",
    "          echo \"${{ secrets.GCP_KEY_BASE64 }}\" | base64 --decode > gcp-key.json\n",
    "          echo \"GCP key file written to gcp-key.json\"\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: gcp-key.json\n",
    "\n",
    "      - name: Pull data from DVC\n",
    "        run: dvc pull -r myremote\n",
    "\n",
    "      - name: Fetch best model from MLflow\n",
    "        env:\n",
    "          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}\n",
    "          MLFLOW_EXPERIMENT_NAME: ${{ secrets.MLFLOW_EXPERIMENT_NAME }}\n",
    "        run: |\n",
    "          echo \"Fetching best model from MLflow experiment...\"\n",
    "          python <<'PYCODE'\n",
    "          import mlflow\n",
    "          from mlflow.tracking import MlflowClient\n",
    "          import os, shutil\n",
    "\n",
    "          client = MlflowClient()\n",
    "          experiment_name = os.getenv(\"MLFLOW_EXPERIMENT_NAME\")\n",
    "          experiment = client.get_experiment_by_name(experiment_name)\n",
    "          if not experiment:\n",
    "              raise SystemExit(f\"Experiment '{experiment_name}' not found in MLflow.\")\n",
    "          \n",
    "          experiment_id = experiment.experiment_id\n",
    "          print(f\"Searching best model from experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "\n",
    "          results = mlflow.search_logged_models(\n",
    "              experiment_ids=[experiment_id],\n",
    "              order_by=[{\"field_name\": \"metrics.accuracy\", \"ascending\": False}],\n",
    "              max_results=1,\n",
    "              output_format=\"list\"\n",
    "          )\n",
    "\n",
    "          if not results:\n",
    "              raise SystemExit(\"No logged models found in this experiment.\")\n",
    "\n",
    "          best_model = results[0]\n",
    "          print(f\"Best model ID: {best_model.model_id}\")\n",
    "          print(f\"Accuracy: {best_model.metrics[0].value}\")\n",
    "\n",
    "          model_uri = f\"models:/{best_model.model_id}\"\n",
    "          output_dir = \"fetched_model\"\n",
    "          if os.path.exists(output_dir):\n",
    "              shutil.rmtree(output_dir)\n",
    "\n",
    "          os.makedirs(output_dir, exist_ok=True)\n",
    "          mlflow.artifacts.download_artifacts(artifact_uri=model_uri, dst_path=output_dir)\n",
    "          print(f\"Saved best model locally at '{output_dir}/'\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Model sanity check & accuracy evaluation\n",
    "        run: |\n",
    "          python <<'PYCODE'\n",
    "          import mlflow.pyfunc\n",
    "          import pandas as pd\n",
    "          from sklearn.model_selection import train_test_split\n",
    "          from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "          model = mlflow.pyfunc.load_model(\"fetched_model\")\n",
    "          df = pd.read_parquet(\"data/stock_data.parquet\")\n",
    "\n",
    "          X = df[['open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14']]\n",
    "          y = df[\"target\"]\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "          y_pred = model.predict(X_test)\n",
    "          acc = accuracy_score(y_test, y_pred)\n",
    "          report = classification_report(y_test, y_pred, output_dict=False)\n",
    "\n",
    "          print(f\"Test Accuracy: {acc:.4f}\")\n",
    "          print(report)\n",
    "\n",
    "          with open(\"accuracy_report.md\", \"w\") as f:\n",
    "              f.write(\"## Model Evaluation Report\\n\\n\")\n",
    "              f.write(f\"**Test Accuracy:** {acc:.4f}\\n\\n\")\n",
    "              f.write(\"```text\\n\")\n",
    "              f.write(\"### Classification Report\\n\\n\")\n",
    "              f.write(report)\n",
    "              f.write(\"\\n```\\n\\n\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Run unit tests and generate Markdown report\n",
    "        run: |\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --junitxml=report.xml > pytest_output.txt\n",
    "\n",
    "          echo \"## Dev Branch Pytest Summary Report\" > dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          echo \"**Date:** $(date)\" >> dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          echo \"### Test Results:\" >> dev_report.md\n",
    "          echo '```' >> dev_report.md\n",
    "          cat pytest_output.txt >> dev_report.md\n",
    "          echo '```' >> dev_report.md\n",
    "          echo \"\" >> dev_report.md\n",
    "          pytest --maxfail=1 --disable-warnings --tb=short -q --cov=. --cov-report=term-missing >> pytest_output.txt 2>&1 || true\n",
    "\n",
    "      - name: Sample Prediction (Feast Online Store)\n",
    "        env:\n",
    "          GOOGLE_APPLICATION_CREDENTIALS: gcp-key.json\n",
    "        run: |\n",
    "          python <<'PYCODE'\n",
    "          from feast import FeatureStore\n",
    "          import pandas as pd\n",
    "          import mlflow.pyfunc\n",
    "\n",
    "          # Load Feature Store\n",
    "          store = FeatureStore(repo_path=\"feature_repo\")\n",
    "\n",
    "          # Detect data version\n",
    "          df = pd.read_parquet(\"data/stock_data.parquet\")\n",
    "          if \"stock_v1_id\" in df.columns:\n",
    "              version = \"v1\"\n",
    "              id_col = \"stock_v1_id\"\n",
    "          elif \"stock_v2_id\" in df.columns:\n",
    "              version = \"v2\"\n",
    "              id_col = \"stock_v2_id\"\n",
    "          else:\n",
    "              raise ValueError(\"No version column found (expected stock_v1_id or stock_v2_id).\")\n",
    "\n",
    "          print(f\" Detected feature view version: {version}\")\n",
    "\n",
    "          # Load model\n",
    "          model = mlflow.pyfunc.load_model(\"fetched_model\")\n",
    "\n",
    "          sample_rows = []\n",
    "          sample_ids = df[id_col].unique()[:5]\n",
    "          for entity_id in sample_ids:\n",
    "              entity_df = pd.DataFrame({id_col: [entity_id]})\n",
    "\n",
    "              print(\"\\n===============================\")\n",
    "              print(\"Requesting online features for entities:\", entity_df.to_dict(orient='records'))\n",
    "\n",
    "              feature_vector = store.get_online_features(\n",
    "                  features=[\n",
    "                      f\"stock_features_{version}:open\",\n",
    "                      f\"stock_features_{version}:high\",\n",
    "                      f\"stock_features_{version}:low\",\n",
    "                      f\"stock_features_{version}:close\",\n",
    "                      f\"stock_features_{version}:volume\",\n",
    "                      f\"stock_features_{version}:ma_15_min\",\n",
    "                      f\"stock_features_{version}:ma_60_min\",\n",
    "                      f\"stock_features_{version}:rsi_14\",\n",
    "                  ],\n",
    "                  entity_rows=entity_df.to_dict(orient=\"records\"),\n",
    "              ).to_df()\n",
    "\n",
    "              print(\"Online features (raw):\")\n",
    "              print(feature_vector)\n",
    "\n",
    "              X = feature_vector.drop(columns=[id_col])\n",
    "              pred = model.predict(X)[0]\n",
    "\n",
    "              # Find true label from df (if available)\n",
    "              true_label = df.loc[df[id_col] == entity_id, \"target\"].values[0] if entity_id in df[id_col].values else \"N/A\"\n",
    "\n",
    "              print(f\"Predicted target: {pred}, True target: {true_label}\")\n",
    "              sample_rows.append({\"Entity\": entity_id, \"True\": true_label, \"Predicted\": pred})\n",
    "\n",
    "          # Append to Markdown report\n",
    "          if sample_rows:\n",
    "              sample_df = pd.DataFrame(sample_rows)\n",
    "              with open(\"accuracy_report.md\", \"a\") as f:\n",
    "                  f.write(\"### Sample Predictions (Feast Online Store)\\n\\n\")\n",
    "                  f.write(sample_df.to_markdown(index=False))\n",
    "                  f.write(\"\\n\\n\")\n",
    "          PYCODE\n",
    "\n",
    "      - name: Set up CML\n",
    "        uses: iterative/setup-cml@v2\n",
    "        with:\n",
    "          version: latest\n",
    "          vega: true\n",
    "        env:\n",
    "          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "\n",
    "      - name: Comment CML Report on commit (push)\n",
    "        if: github.event_name == 'push'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> dev_report.md\n",
    "          cml comment create --target=commit --publish dev_report.md\n",
    "\n",
    "      - name: Comment CML Report on PR (pull request)\n",
    "        if: github.event_name == 'pull_request'\n",
    "        env:\n",
    "          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n",
    "        run: |\n",
    "          cat accuracy_report.md >> dev_report.md\n",
    "          cml comment create --target=pr --publish dev_report.md\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure GCS as Remote Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'myremote' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d myremote {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote modify myremote credentialpath iitmbs-mlops-a99d6ce657ac.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ADANIENT__EQ__NSE__NSE__MINUTE.csv\n",
      "Processing: ABFRL__EQ__NSE__NSE__MINUTE.csv\n",
      "\n",
      " Full dataset saved to: data/stock_data_full.parquet\n",
      "Total rows: 730865\n",
      " Sampled dataset (1000 rows) saved to: data/stock_data.parquet\n"
     ]
    }
   ],
   "source": [
    "! python src/process_data_v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_parquet_data = \"data/stock_data.parquet\"\n",
    "df = pd.read_parquet(local_parquet_data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>stock_v1_id</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ma_15_min</th>\n",
       "      <th>ma_60_min</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-06 14:22:00+05:30</td>\n",
       "      <td>ABFRL-v1-24305</td>\n",
       "      <td>159.50</td>\n",
       "      <td>159.55</td>\n",
       "      <td>159.40</td>\n",
       "      <td>159.40</td>\n",
       "      <td>402.0</td>\n",
       "      <td>159.390000</td>\n",
       "      <td>158.860000</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-24 14:10:00+05:30</td>\n",
       "      <td>ABFRL-v1-305149</td>\n",
       "      <td>120.15</td>\n",
       "      <td>120.50</td>\n",
       "      <td>120.00</td>\n",
       "      <td>120.25</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>120.566667</td>\n",
       "      <td>120.926667</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-22 09:40:00+05:30</td>\n",
       "      <td>ADANIENT-v1-35275</td>\n",
       "      <td>121.65</td>\n",
       "      <td>121.65</td>\n",
       "      <td>121.45</td>\n",
       "      <td>121.50</td>\n",
       "      <td>9190.0</td>\n",
       "      <td>121.956667</td>\n",
       "      <td>121.984167</td>\n",
       "      <td>36.842105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-16 13:00:00+05:30</td>\n",
       "      <td>ABFRL-v1-272079</td>\n",
       "      <td>229.35</td>\n",
       "      <td>229.35</td>\n",
       "      <td>229.35</td>\n",
       "      <td>229.35</td>\n",
       "      <td>333.0</td>\n",
       "      <td>229.333333</td>\n",
       "      <td>229.262500</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-05 11:33:00+05:30</td>\n",
       "      <td>ABFRL-v1-31261</td>\n",
       "      <td>167.30</td>\n",
       "      <td>167.30</td>\n",
       "      <td>167.20</td>\n",
       "      <td>167.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>167.520000</td>\n",
       "      <td>168.154167</td>\n",
       "      <td>36.734694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2018-11-15 11:20:00+05:30</td>\n",
       "      <td>ADANIENT-v1-172867</td>\n",
       "      <td>165.00</td>\n",
       "      <td>165.20</td>\n",
       "      <td>164.95</td>\n",
       "      <td>165.05</td>\n",
       "      <td>4058.0</td>\n",
       "      <td>164.976667</td>\n",
       "      <td>164.920000</td>\n",
       "      <td>52.173913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2017-12-05 14:53:00+05:30</td>\n",
       "      <td>ABFRL-v1-86075</td>\n",
       "      <td>163.05</td>\n",
       "      <td>163.40</td>\n",
       "      <td>163.05</td>\n",
       "      <td>163.25</td>\n",
       "      <td>270.0</td>\n",
       "      <td>163.143333</td>\n",
       "      <td>163.290000</td>\n",
       "      <td>58.620690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2018-08-24 12:53:00+05:30</td>\n",
       "      <td>ABFRL-v1-153077</td>\n",
       "      <td>192.30</td>\n",
       "      <td>192.75</td>\n",
       "      <td>192.30</td>\n",
       "      <td>192.75</td>\n",
       "      <td>984.0</td>\n",
       "      <td>192.543333</td>\n",
       "      <td>191.920000</td>\n",
       "      <td>60.256410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2019-10-31 11:04:00+05:30</td>\n",
       "      <td>ADANIENT-v1-260286</td>\n",
       "      <td>199.15</td>\n",
       "      <td>199.15</td>\n",
       "      <td>198.80</td>\n",
       "      <td>198.85</td>\n",
       "      <td>13169.0</td>\n",
       "      <td>199.373333</td>\n",
       "      <td>198.677500</td>\n",
       "      <td>27.659574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2018-03-09 14:05:00+05:30</td>\n",
       "      <td>ADANIENT-v1-110030</td>\n",
       "      <td>162.25</td>\n",
       "      <td>162.25</td>\n",
       "      <td>162.00</td>\n",
       "      <td>162.10</td>\n",
       "      <td>8210.0</td>\n",
       "      <td>162.260000</td>\n",
       "      <td>162.808333</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_timestamp         stock_v1_id    open    high     low  \\\n",
       "0   2017-04-06 14:22:00+05:30      ABFRL-v1-24305  159.50  159.55  159.40   \n",
       "1   2020-04-24 14:10:00+05:30     ABFRL-v1-305149  120.15  120.50  120.00   \n",
       "2   2017-05-22 09:40:00+05:30   ADANIENT-v1-35275  121.65  121.65  121.45   \n",
       "3   2019-12-16 13:00:00+05:30     ABFRL-v1-272079  229.35  229.35  229.35   \n",
       "4   2017-05-05 11:33:00+05:30      ABFRL-v1-31261  167.30  167.30  167.20   \n",
       "..                        ...                 ...     ...     ...     ...   \n",
       "995 2018-11-15 11:20:00+05:30  ADANIENT-v1-172867  165.00  165.20  164.95   \n",
       "996 2017-12-05 14:53:00+05:30      ABFRL-v1-86075  163.05  163.40  163.05   \n",
       "997 2018-08-24 12:53:00+05:30     ABFRL-v1-153077  192.30  192.75  192.30   \n",
       "998 2019-10-31 11:04:00+05:30  ADANIENT-v1-260286  199.15  199.15  198.80   \n",
       "999 2018-03-09 14:05:00+05:30  ADANIENT-v1-110030  162.25  162.25  162.00   \n",
       "\n",
       "      close   volume   ma_15_min   ma_60_min     rsi_14  target  \n",
       "0    159.40    402.0  159.390000  158.860000  58.333333       0  \n",
       "1    120.25   2487.0  120.566667  120.926667  29.166667       0  \n",
       "2    121.50   9190.0  121.956667  121.984167  36.842105       0  \n",
       "3    229.35    333.0  229.333333  229.262500  55.555556       0  \n",
       "4    167.20    100.0  167.520000  168.154167  36.734694       0  \n",
       "..      ...      ...         ...         ...        ...     ...  \n",
       "995  165.05   4058.0  164.976667  164.920000  52.173913       0  \n",
       "996  163.25    270.0  163.143333  163.290000  58.620690       0  \n",
       "997  192.75    984.0  192.543333  191.920000  60.256410       0  \n",
       "998  198.85  13169.0  199.373333  198.677500  27.659574       0  \n",
       "999  162.10   8210.0  162.260000  162.808333  35.294118       1  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Data with DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/stock_data.parquet |0.00 [00:00,  \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding data/stock_data.parquet to cach0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/stock_0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...||1/1 [00:00, 11.03file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/stock_data.parquet.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc add {local_parquet_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |1.00 [00:00,  185entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'iitmbs-mlops-21f1000344/files/md5'| |0/? [00:00<?,    ?f\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gs                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/67.6k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%||/home/jupyter/.dvc/cache/f67.6k/67.6k [00:00<00:00,     554kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%||Pushing to gs                     1/1 [00:00<00:00,  5.48file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_14817/915146763.py:4: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity 'stock_v1_id'.\n",
      "  entity = Entity(name=\"stock_v1_id\", join_keys=[\"stock_v1_id\"])\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Define Feast Feature Store config\n",
    "# --------------------------\n",
    "entity = Entity(name=\"stock_v1_id\", join_keys=[\"stock_v1_id\"])\n",
    "\n",
    "stock_source = FileSource(\n",
    "    path=os.path.abspath(local_parquet_data), # offline store data location\n",
    "    timestamp_field=\"event_timestamp\",\n",
    ")\n",
    "\n",
    "stock_fv = FeatureView(\n",
    "    name=\"stock_features_v1\",\n",
    "    entities=[entity],\n",
    "    ttl=timedelta(days=3650),\n",
    "    schema=[\n",
    "        Field(name=\"open\", dtype=Float64),\n",
    "        Field(name=\"high\", dtype=Float64),\n",
    "        Field(name=\"low\", dtype=Float64),\n",
    "        Field(name=\"close\", dtype=Float64),\n",
    "        Field(name=\"volume\", dtype=Float64),\n",
    "        Field(name=\"ma_15_min\", dtype=Float64),\n",
    "        Field(name=\"ma_60_min\", dtype=Float64),\n",
    "        Field(name=\"rsi_14\", dtype=Float64),\n",
    "        Field(name=\"target\", dtype=Int64),\n",
    "    ],\n",
    "    online=True,\n",
    "    source=stock_source,\n",
    "    tags={\n",
    "        \"stock_data_version\": \"v1\",\n",
    "        \"description\": \"Features derived from v1 of stock dataset\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Initialize Feast Store and apply definitions\n",
    "# --------------------------\n",
    "store = FeatureStore(repo_path=\"feature_repo\")\n",
    "store.apply([entity, stock_fv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing features...\n",
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2021-01-01 10:52:00+05:30\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mstock_features_v1\u001b[0m from \u001b[1m\u001b[32m2015-11-10 12:41:30+00:00\u001b[0m to \u001b[1m\u001b[32m2021-01-01 10:52:00+05:30\u001b[0m:\n"
     ]
    }
   ],
   "source": [
    "# Materialize stock_features_v1 into online store\n",
    "end_time = df['event_timestamp'].max()\n",
    "print(\"Materializing features...\")\n",
    "store.materialize_incremental(\n",
    "    end_date=end_time,\n",
    "    feature_views=[\"stock_features_v1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup MLFlow Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SSH into the VM and run the following command to start MLFlow server\n",
    "# pip install mlflow\n",
    "# mlflow server --host 0.0.0.0 --port 8100 --allowed-hosts '*'  --cors-allowed-origins '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple RandomForestClassifier model\n",
    "Build a RandomForestClassifier model on iris data and log parameters, metrics, model, and artifacts to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=10, max_depth=3, version=v1\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v1_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.38 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v1\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp       stock_v1_id  ...   rsi_14__  target__\n",
      "0 2017-01-02 04:47:00+00:00       ABFRL-v1-62  ...  54.545455         0\n",
      "1 2017-01-04 06:43:00+00:00      ABFRL-v1-928  ...  41.666667         0\n",
      "2 2017-01-05 08:31:00+00:00     ABFRL-v1-1411  ...  41.176471         0\n",
      "3 2017-01-06 06:17:00+00:00  ADANIENT-v1-1652  ...  44.444444         0\n",
      "4 2017-01-06 07:06:00+00:00     ABFRL-v1-1701  ...  47.826087         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Using stratified split...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.620\n",
      "Precision: 0.594\n",
      "Recall: 0.620\n",
      "F1 Score: 0.518\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 11:34:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 11:34:21 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 6\n",
      "Created version '6' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run rare-hawk-681 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/48208c4b8a784403adce75079a5a6bea\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 16.4 KiB/ 16.4 KiB]                                                \n",
      "Operation completed over 1 objects/16.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 10 --max_depth 3 --random_state 42 --version \"v1\" --stratify YES\n",
    "! gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=20, max_depth=3, version=v1\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v1_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.38 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v1\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp       stock_v1_id  ...   rsi_14__  target__\n",
      "0 2017-01-02 04:47:00+00:00       ABFRL-v1-62  ...  54.545455         0\n",
      "1 2017-01-04 06:43:00+00:00      ABFRL-v1-928  ...  41.666667         0\n",
      "2 2017-01-05 08:31:00+00:00     ABFRL-v1-1411  ...  41.176471         0\n",
      "3 2017-01-06 06:17:00+00:00  ADANIENT-v1-1652  ...  44.444444         0\n",
      "4 2017-01-06 07:06:00+00:00     ABFRL-v1-1701  ...  47.826087         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Using stratified split...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.600\n",
      "Precision: 0.486\n",
      "Recall: 0.600\n",
      "F1 Score: 0.478\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 11:34:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 11:34:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 7\n",
      "Created version '7' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run merciful-panda-497 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/2399e25d3abd48ca8578fb94e9efd392\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 31.7 KiB/ 31.7 KiB]                                                \n",
      "Operation completed over 1 objects/31.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 20 --max_depth 3 --random_state 7 --version \"v1\" --stratify YES\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=100, max_depth=5, version=v1\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v1_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.38 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v1\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp       stock_v1_id  ...   rsi_14__  target__\n",
      "0 2017-01-02 04:47:00+00:00       ABFRL-v1-62  ...  54.545455         0\n",
      "1 2017-01-04 06:43:00+00:00      ABFRL-v1-928  ...  41.666667         0\n",
      "2 2017-01-05 08:31:00+00:00     ABFRL-v1-1411  ...  41.176471         0\n",
      "3 2017-01-06 06:17:00+00:00  ADANIENT-v1-1652  ...  44.444444         0\n",
      "4 2017-01-06 07:06:00+00:00     ABFRL-v1-1701  ...  47.826087         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.590\n",
      "Precision: 0.527\n",
      "Recall: 0.590\n",
      "F1 Score: 0.484\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 11:34:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 11:35:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 8\n",
      "Created version '8' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run industrious-mink-966 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/c6b9bc900ea94294ae155c84b51ce5fc\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][361.6 KiB/361.6 KiB]                                                \n",
      "Operation completed over 1 objects/361.6 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 100 --max_depth 5 --random_state 7 --version \"v1\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=250, max_depth=3, version=v1\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v1_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.38 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v1\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp       stock_v1_id  ...   rsi_14__  target__\n",
      "0 2017-01-02 04:47:00+00:00       ABFRL-v1-62  ...  54.545455         0\n",
      "1 2017-01-04 06:43:00+00:00      ABFRL-v1-928  ...  41.666667         0\n",
      "2 2017-01-05 08:31:00+00:00     ABFRL-v1-1411  ...  41.176471         0\n",
      "3 2017-01-06 06:17:00+00:00  ADANIENT-v1-1652  ...  44.444444         0\n",
      "4 2017-01-06 07:06:00+00:00     ABFRL-v1-1701  ...  47.826087         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.590\n",
      "Precision: 0.458\n",
      "Recall: 0.590\n",
      "F1 Score: 0.454\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 11:35:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 11:35:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 9\n",
      "Created version '9' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run kindly-tern-638 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/bcec26de9a7b44198abca90ef23d3b5c\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][361.9 KiB/361.9 KiB]                                                \n",
      "Operation completed over 1 objects/361.9 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 250 --max_depth 3 --random_state 7 --version \"v1\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/jupyter\n",
      "plugins: anyio-4.11.0, typeguard-4.4.4, hydra-core-1.3.2\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_data_validation.py::test_parquet_data_integrity \u001b[32mPASSED\u001b[0m\u001b[32m        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.53s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest tests/test_data_validation.py -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/jupyter\n",
      "plugins: anyio-4.11.0, typeguard-4.4.4, hydra-core-1.3.2\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_model_evaluation.py::test_model_performance_parquet \u001b[32mPASSED\u001b[0m\u001b[32m    [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 1.46s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest tests/test_model_evaluation.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to Git and Commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.dvc/\u001b[m\n",
      "\t\u001b[31m.dvcignore\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.github/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31mfeature_repo/\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\t\u001b[31mrequirements.txt\u001b[m\n",
      "\t\u001b[31msrc/\u001b[m\n",
      "\t\u001b[31mtests/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'dev'\n"
     ]
    }
   ],
   "source": [
    "!git checkout -b dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.dvc/\u001b[m\n",
      "\t\u001b[31m.dvcignore\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.github/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31mfeature_repo/\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\t\u001b[31mrequirements.txt\u001b[m\n",
      "\t\u001b[31msrc/\u001b[m\n",
      "\t\u001b[31mtests/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following paths are ignored by one of your .gitignore files:\n",
      "data/stock_data.parquet\n",
      "\u001b[33mhint: Use -f if you really want to add them.\u001b[m\n",
      "\u001b[33mhint: Turn this message off by running\u001b[m\n",
      "\u001b[33mhint: \"git config advice.addIgnoredFile false\"\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! git add artifacts/ data/stock_data.parquet data/stock_data.parquet.dvc feature_repo/ src/ tests/ .dvc/ .github/ requirements.txt .gitconfig .dvcignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\t\u001b[32mnew file:   .dvc/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   .dvc/config\u001b[m\n",
      "\t\u001b[32mnew file:   .dvcignore\u001b[m\n",
      "\t\u001b[32mnew file:   .gitconfig\u001b[m\n",
      "\t\u001b[32mnew file:   .github/workflows/ci-dev.yml\u001b[m\n",
      "\t\u001b[32mnew file:   .github/workflows/ci-main.yml\u001b[m\n",
      "\t\u001b[32mnew file:   artifacts/model.joblib\u001b[m\n",
      "\t\u001b[32mnew file:   data/stock_data.parquet.dvc\u001b[m\n",
      "\t\u001b[32mnew file:   feature_repo/.ipynb_checkpoints/feature_store-checkpoint.yaml\u001b[m\n",
      "\t\u001b[32mnew file:   feature_repo/feature_store.yaml\u001b[m\n",
      "\t\u001b[32mnew file:   feature_repo/online_store.db\u001b[m\n",
      "\t\u001b[32mnew file:   requirements.txt\u001b[m\n",
      "\t\u001b[32mnew file:   src/.ipynb_checkpoints/process_data_v1-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   src/.ipynb_checkpoints/process_data_v2-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   src/.ipynb_checkpoints/train-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   src/process_data_v1.py\u001b[m\n",
      "\t\u001b[32mnew file:   src/process_data_v2.py\u001b[m\n",
      "\t\u001b[32mnew file:   src/train.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/.ipynb_checkpoints/test_model_evaluation-checkpoint.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[32mnew file:   tests/__pycache__/test_model_evaluation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[32mnew file:   tests/test_data_validation.py\u001b[m\n",
      "\t\u001b[32mnew file:   tests/test_model_evaluation.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31mdata/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/stock_data_full.parquet\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev (root-commit) 95e9b39] Commit to both dev and main branch. First iteration done with 150 rows of iris data\n",
      " 24 files changed, 1472 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n",
      " create mode 100644 .gitconfig\n",
      " create mode 100644 .github/workflows/ci-dev.yml\n",
      " create mode 100644 .github/workflows/ci-main.yml\n",
      " create mode 100644 artifacts/model.joblib\n",
      " create mode 100644 data/stock_data.parquet.dvc\n",
      " create mode 100644 feature_repo/.ipynb_checkpoints/feature_store-checkpoint.yaml\n",
      " create mode 100644 feature_repo/feature_store.yaml\n",
      " create mode 100644 feature_repo/online_store.db\n",
      " create mode 100644 requirements.txt\n",
      " create mode 100644 src/.ipynb_checkpoints/process_data_v1-checkpoint.py\n",
      " create mode 100644 src/.ipynb_checkpoints/process_data_v2-checkpoint.py\n",
      " create mode 100644 src/.ipynb_checkpoints/train-checkpoint.py\n",
      " create mode 100644 src/process_data_v1.py\n",
      " create mode 100644 src/process_data_v2.py\n",
      " create mode 100644 src/train.py\n",
      " create mode 100644 tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\n",
      " create mode 100644 tests/.ipynb_checkpoints/test_model_evaluation-checkpoint.py\n",
      " create mode 100644 tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\n",
      " create mode 100644 tests/__pycache__/test_model_evaluation.cpython-310-pytest-8.4.2.pyc\n",
      " create mode 100644 tests/test_data_validation.py\n",
      " create mode 100644 tests/test_model_evaluation.py\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"Commit to both dev and main branch. First iteration done with 150 rows of iris data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit 95e9b39fc8607322790cb5f32d0a3e8fbaad8230\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mdev\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Satvik Chandrakar <chandrakarsatvik@gmail.com>\n",
      "Date:   Fri Nov 7 12:46:39 2025 +0000\n",
      "\n",
      "    Commit to both dev and main branch. First iteration done with 150 rows of iris data\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git remote add origin https://Satvik-ai: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@github.com/Satvik-ai/stock_test.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 32, done.\n",
      "Counting objects: 100% (32/32), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (29/29), done.\n",
      "Writing objects: 100% (32/32), 358.65 KiB | 5.27 MiB/s, done.\n",
      "Total 32 (delta 2), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (2/2), done.\u001b[K\n",
      "To https://github.com/Satvik-ai/stock_test.git\n",
      " * [new branch]      dev -> dev\n",
      "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to a new branch 'main'\n"
     ]
    }
   ],
   "source": [
    "!git checkout -b main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31mdata/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/stock_data_full.parquet\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 (delta 0), reused 0 (delta 0), pack-reused 0\n",
      "remote: \n",
      "remote: Create a pull request for 'main' on GitHub by visiting:\u001b[K\n",
      "remote:      https://github.com/Satvik-ai/stock_test/pull/new/main\u001b[K\n",
      "remote: \n",
      "To https://github.com/Satvik-ai/stock_test.git\n",
      " * [new branch]      main -> main\n",
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytest Code Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the below given code to test_data_validation.py, push the pytest code changes to Dev branch and raise Pull Request to main branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_numeric_columns_are_numeric_parquet():\n",
    "#     df = pd.read_parquet(\"data/stock_data.parquet\")\n",
    "#     numeric_cols = ['open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14']\n",
    "\n",
    "#     for col in numeric_cols:\n",
    "#         assert pd.api.types.is_numeric_dtype(df[col]), f\"Column {col} is not numeric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/jupyter\n",
      "plugins: anyio-4.11.0, typeguard-4.4.4, hydra-core-1.3.2\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_data_validation.py::test_parquet_data_integrity \u001b[32mPASSED\u001b[0m\u001b[32m        [ 50%]\u001b[0m\n",
      "tests/test_data_validation.py::test_numeric_columns_are_numeric_parquet \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.54s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Local test\n",
    "! pytest tests/test_data_validation.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Version 2 of Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ADANIGAS__EQ__NSE__NSE__MINUTE.csv\n",
      "Processing: ABCAPITAL__EQ__NSE__NSE__MINUTE.csv\n",
      "\n",
      " Full dataset saved to: data/stock_data_full.parquet\n",
      "Total rows: 197833\n",
      " Sampled dataset (1000 rows) saved to: data/stock_data.parquet\n"
     ]
    }
   ],
   "source": [
    "! python src/process_data_v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_parquet_data = \"data/stock_data.parquet\"\n",
    "df = pd.read_parquet(local_parquet_data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>stock_v2_id</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ma_15_min</th>\n",
       "      <th>ma_60_min</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-14 12:01:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-47447</td>\n",
       "      <td>117.35</td>\n",
       "      <td>117.55</td>\n",
       "      <td>117.35</td>\n",
       "      <td>117.55</td>\n",
       "      <td>239.0</td>\n",
       "      <td>117.520000</td>\n",
       "      <td>117.258333</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-12 09:45:00+05:30</td>\n",
       "      <td>ABCAPITAL-v2-10501</td>\n",
       "      <td>179.85</td>\n",
       "      <td>180.20</td>\n",
       "      <td>179.85</td>\n",
       "      <td>180.05</td>\n",
       "      <td>4419.0</td>\n",
       "      <td>179.550000</td>\n",
       "      <td>179.205000</td>\n",
       "      <td>79.310345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-12 15:29:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-63405</td>\n",
       "      <td>163.15</td>\n",
       "      <td>163.25</td>\n",
       "      <td>163.10</td>\n",
       "      <td>163.20</td>\n",
       "      <td>3146.0</td>\n",
       "      <td>163.220000</td>\n",
       "      <td>163.623333</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-18 10:55:00+05:30</td>\n",
       "      <td>ABCAPITAL-v2-4196</td>\n",
       "      <td>203.00</td>\n",
       "      <td>203.00</td>\n",
       "      <td>202.75</td>\n",
       "      <td>202.75</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>202.843333</td>\n",
       "      <td>202.285000</td>\n",
       "      <td>43.902439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05 12:50:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-38871</td>\n",
       "      <td>130.65</td>\n",
       "      <td>130.65</td>\n",
       "      <td>130.65</td>\n",
       "      <td>130.65</td>\n",
       "      <td>44.0</td>\n",
       "      <td>130.663333</td>\n",
       "      <td>130.395833</td>\n",
       "      <td>51.351351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2020-03-06 12:51:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-123307</td>\n",
       "      <td>126.15</td>\n",
       "      <td>126.25</td>\n",
       "      <td>126.15</td>\n",
       "      <td>126.25</td>\n",
       "      <td>700.0</td>\n",
       "      <td>126.380000</td>\n",
       "      <td>125.474167</td>\n",
       "      <td>52.777778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2019-07-23 11:15:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-65776</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.35</td>\n",
       "      <td>165.35</td>\n",
       "      <td>100.0</td>\n",
       "      <td>165.423333</td>\n",
       "      <td>165.770000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2020-08-11 11:07:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-162578</td>\n",
       "      <td>161.00</td>\n",
       "      <td>161.55</td>\n",
       "      <td>161.00</td>\n",
       "      <td>161.40</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>162.030000</td>\n",
       "      <td>162.783333</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2020-03-09 11:20:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-123591</td>\n",
       "      <td>122.25</td>\n",
       "      <td>122.50</td>\n",
       "      <td>122.20</td>\n",
       "      <td>122.45</td>\n",
       "      <td>964.0</td>\n",
       "      <td>122.056667</td>\n",
       "      <td>122.256667</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2019-04-05 10:49:00+05:30</td>\n",
       "      <td>ADANIGAS-v2-38750</td>\n",
       "      <td>131.45</td>\n",
       "      <td>131.45</td>\n",
       "      <td>131.45</td>\n",
       "      <td>131.45</td>\n",
       "      <td>24.0</td>\n",
       "      <td>131.663333</td>\n",
       "      <td>131.605000</td>\n",
       "      <td>37.142857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_timestamp         stock_v2_id    open    high     low  \\\n",
       "0   2019-05-14 12:01:00+05:30   ADANIGAS-v2-47447  117.35  117.55  117.35   \n",
       "1   2017-10-12 09:45:00+05:30  ABCAPITAL-v2-10501  179.85  180.20  179.85   \n",
       "2   2019-07-12 15:29:00+05:30   ADANIGAS-v2-63405  163.15  163.25  163.10   \n",
       "3   2017-09-18 10:55:00+05:30   ABCAPITAL-v2-4196  203.00  203.00  202.75   \n",
       "4   2019-04-05 12:50:00+05:30   ADANIGAS-v2-38871  130.65  130.65  130.65   \n",
       "..                        ...                 ...     ...     ...     ...   \n",
       "995 2020-03-06 12:51:00+05:30  ADANIGAS-v2-123307  126.15  126.25  126.15   \n",
       "996 2019-07-23 11:15:00+05:30   ADANIGAS-v2-65776  165.35  165.35  165.35   \n",
       "997 2020-08-11 11:07:00+05:30  ADANIGAS-v2-162578  161.00  161.55  161.00   \n",
       "998 2020-03-09 11:20:00+05:30  ADANIGAS-v2-123591  122.25  122.50  122.20   \n",
       "999 2019-04-05 10:49:00+05:30   ADANIGAS-v2-38750  131.45  131.45  131.45   \n",
       "\n",
       "      close  volume   ma_15_min   ma_60_min     rsi_14  target  \n",
       "0    117.55   239.0  117.520000  117.258333  53.333333       1  \n",
       "1    180.05  4419.0  179.550000  179.205000  79.310345       1  \n",
       "2    163.20  3146.0  163.220000  163.623333  46.153846       1  \n",
       "3    202.75  3306.0  202.843333  202.285000  43.902439       1  \n",
       "4    130.65    44.0  130.663333  130.395833  51.351351       0  \n",
       "..      ...     ...         ...         ...        ...     ...  \n",
       "995  126.25   700.0  126.380000  125.474167  52.777778       0  \n",
       "996  165.35   100.0  165.423333  165.770000  37.500000       0  \n",
       "997  161.40  3346.0  162.030000  162.783333  26.666667       1  \n",
       "998  122.45   964.0  122.056667  122.256667  71.428571       0  \n",
       "999  131.45    24.0  131.663333  131.605000  37.142857       1  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Data Version 2 with DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/stock_data.parquet |0.00 [00:00,  \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding data/stock_data.parquet to cach0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/stock_0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...||1/1 [00:00, 12.55file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/stock_data.parquet.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc add {local_parquet_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |1.00 [00:00,  178entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'iitmbs-mlops-21f1000344/files/md5'| |0/? [00:00<?,    ?f\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gs                         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/66.7k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%||/home/jupyter/.dvc/cache/f66.7k/66.7k [00:00<00:00,     551kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%||Pushing to gs                     1/1 [00:00<00:00,  6.04file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "1 file pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_14817/349546511.py:4: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity 'stock_v2_id'.\n",
      "  entity = Entity(name=\"stock_v2_id\", join_keys=[\"stock_v2_id\"])\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Define Feast Feature Store config\n",
    "# --------------------------\n",
    "entity = Entity(name=\"stock_v2_id\", join_keys=[\"stock_v2_id\"])\n",
    "\n",
    "stock_source = FileSource(\n",
    "    path=os.path.abspath(local_parquet_data), # offline store data location\n",
    "    timestamp_field=\"event_timestamp\",\n",
    ")\n",
    "\n",
    "stock_fv = FeatureView(\n",
    "    name=\"stock_features_v2\",\n",
    "    entities=[entity],\n",
    "    ttl=timedelta(days=3650),\n",
    "    schema=[\n",
    "        Field(name=\"open\", dtype=Float64),\n",
    "        Field(name=\"high\", dtype=Float64),\n",
    "        Field(name=\"low\", dtype=Float64),\n",
    "        Field(name=\"close\", dtype=Float64),\n",
    "        Field(name=\"volume\", dtype=Float64),\n",
    "        Field(name=\"ma_15_min\", dtype=Float64),\n",
    "        Field(name=\"ma_60_min\", dtype=Float64),\n",
    "        Field(name=\"rsi_14\", dtype=Float64),\n",
    "        Field(name=\"target\", dtype=Int64),\n",
    "    ],\n",
    "    online=True,\n",
    "    source=stock_source,\n",
    "    tags={\n",
    "        \"stock_data_version\": \"v2\",\n",
    "        \"description\": \"Features derived from v2 of stock dataset\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store.apply([entity, stock_fv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializing features...\n",
      "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2021-01-01 13:33:00+05:30\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
      "\n",
      "\u001b[1m\u001b[32mstock_features_v2\u001b[0m from \u001b[1m\u001b[32m2015-11-10 13:01:14+00:00\u001b[0m to \u001b[1m\u001b[32m2021-01-01 13:33:00+05:30\u001b[0m:\n"
     ]
    }
   ],
   "source": [
    "# Materialize iris_features_v2 into online store\n",
    "end_time = df['event_timestamp'].max()\n",
    "print(\"Materializing features...\")\n",
    "store.materialize_incremental(\n",
    "    end_date=end_time,\n",
    "    feature_views=[\"stock_features_v2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model with Data Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=10, max_depth=3, version=v2\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v2_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.03 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v2\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp        stock_v2_id  ...   rsi_14__  target__\n",
      "0 2017-09-07 04:14:00+00:00  ABCAPITAL-v2-1500  ...  85.714286         1\n",
      "1 2017-09-07 05:12:00+00:00  ABCAPITAL-v2-1558  ...  78.125000         0\n",
      "2 2017-09-08 06:53:00+00:00  ABCAPITAL-v2-2034  ...  54.929577         0\n",
      "3 2017-09-08 07:17:00+00:00  ABCAPITAL-v2-2058  ...  75.000000         0\n",
      "4 2017-09-11 04:44:00+00:00  ABCAPITAL-v2-2280  ...  35.514019         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Using stratified split...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.615\n",
      "Precision: 0.383\n",
      "Recall: 0.615\n",
      "F1 Score: 0.472\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 13:04:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 13:04:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 10\n",
      "Created version '10' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run unruly-ox-652 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/7acc216ecaa34f57b3528929c718f252\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 16.1 KiB/ 16.1 KiB]                                                \n",
      "Operation completed over 1 objects/16.1 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 10 --max_depth 3 --random_state 42 --version \"v2\" --stratify YES\n",
    "! gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=20, max_depth=3, version=v2\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v2_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.03 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v2\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp        stock_v2_id  ...   rsi_14__  target__\n",
      "0 2017-09-07 04:14:00+00:00  ABCAPITAL-v2-1500  ...  85.714286         1\n",
      "1 2017-09-07 05:12:00+00:00  ABCAPITAL-v2-1558  ...  78.125000         0\n",
      "2 2017-09-08 06:53:00+00:00  ABCAPITAL-v2-2034  ...  54.929577         0\n",
      "3 2017-09-08 07:17:00+00:00  ABCAPITAL-v2-2058  ...  75.000000         0\n",
      "4 2017-09-11 04:44:00+00:00  ABCAPITAL-v2-2280  ...  35.514019         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Using stratified split...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.620\n",
      "Precision: 0.384\n",
      "Recall: 0.620\n",
      "F1 Score: 0.475\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 13:04:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 13:04:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 11\n",
      "Created version '11' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run monumental-kit-406 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/a165318199ec4a779b54c71ac77764bd\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 30.3 KiB/ 30.3 KiB]                                                \n",
      "Operation completed over 1 objects/30.3 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 20 --max_depth 3 --random_state 7 --version \"v2\" --stratify YES\n",
    "! gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=100, max_depth=5, version=v2\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v2_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.03 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v2\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp        stock_v2_id  ...   rsi_14__  target__\n",
      "0 2017-09-07 04:14:00+00:00  ABCAPITAL-v2-1500  ...  85.714286         1\n",
      "1 2017-09-07 05:12:00+00:00  ABCAPITAL-v2-1558  ...  78.125000         0\n",
      "2 2017-09-08 06:53:00+00:00  ABCAPITAL-v2-2034  ...  54.929577         0\n",
      "3 2017-09-08 07:17:00+00:00  ABCAPITAL-v2-2058  ...  75.000000         0\n",
      "4 2017-09-11 04:44:00+00:00  ABCAPITAL-v2-2280  ...  35.514019         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.620\n",
      "Precision: 0.559\n",
      "Recall: 0.620\n",
      "F1 Score: 0.510\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 13:05:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 13:05:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 12\n",
      "Created version '12' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run vaunted-penguin-250 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/74dc3c3ab7d04d92808a76b2122d02c4\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][346.4 KiB/346.4 KiB]                                                \n",
      "Operation completed over 1 objects/346.4 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 100 --max_depth 5 --random_state 7 --version \"v2\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting training script...\n",
      "Parameters: n_estimators=250, max_depth=3, version=v2\n",
      "==================================================\n",
      "\n",
      "[1/6] Setting up MLflow...\n",
      "MLflow tracking URI: http://127.0.0.1:8100\n",
      " MLflow setup successful\n",
      "\n",
      "[2/6] Loading local data...\n",
      "Loading from: data/stock_data.parquet\n",
      " Data loaded. Shape: (1000, 11)\n",
      "Columns: ['event_timestamp', 'stock_v2_id', 'open', 'high', 'low', 'close', 'volume', 'ma_15_min', 'ma_60_min', 'rsi_14', 'target']\n",
      "\n",
      "[3/6] Initializing Feast Feature Store...\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      " Feast store initialized\n",
      "Memory before fetch: 14.03 GB\n",
      "\n",
      "[4/6] Fetching features from Feast...\n",
      "Requesting feature view: stock_features_v2\n",
      " Features fetched successfully\n",
      "Training data shape after dropna: (1000, 20)\n",
      "            event_timestamp        stock_v2_id  ...   rsi_14__  target__\n",
      "0 2017-09-07 04:14:00+00:00  ABCAPITAL-v2-1500  ...  85.714286         1\n",
      "1 2017-09-07 05:12:00+00:00  ABCAPITAL-v2-1558  ...  78.125000         0\n",
      "2 2017-09-08 06:53:00+00:00  ABCAPITAL-v2-2034  ...  54.929577         0\n",
      "3 2017-09-08 07:17:00+00:00  ABCAPITAL-v2-2058  ...  75.000000         0\n",
      "4 2017-09-11 04:44:00+00:00  ABCAPITAL-v2-2280  ...  35.514019         0\n",
      "\n",
      "[5 rows x 20 columns]\n",
      "\n",
      "[5/6] Training RandomForestClassifier...\n",
      "Training set size: 800, Test set size: 200\n",
      "Fitting model...\n",
      "Making predictions...\n",
      "Accuracy: 0.620\n",
      "Precision: 0.515\n",
      "Recall: 0.620\n",
      "F1 Score: 0.487\n",
      "Model saved to artifacts/model.joblib\n",
      "2025/11/07 13:05:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Stock-Classifier-RF' already exists. Creating a new version of this model...\n",
      "2025/11/07 13:05:22 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Stock-Classifier-RF, version 13\n",
      "Created version '13' of model 'Stock-Classifier-RF'.\n",
      " Training and logging complete!\n",
      " View run nosy-ray-38 at: http://127.0.0.1:8100/#/experiments/599008182471864491/runs/a5130550ef7f4d329813aa524a0ff74d\n",
      " View experiment at: http://127.0.0.1:8100/#/experiments/599008182471864491\n",
      "Copying file://artifacts/model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][361.6 KiB/361.6 KiB]                                                \n",
      "Operation completed over 1 objects/361.6 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! python src/train.py --n_estimators 250 --max_depth 3 --random_state 7 --version \"v2\" --stratify NO\n",
    "!gsutil cp artifacts/model.joblib {BUCKET_URI}/models/ #Upload Model Artifacts to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to Git, Commit and Push to Dev Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\tartifacts/model.joblib\n",
      "M\tdata/stock_data.parquet.dvc\n",
      "M\tfeature_repo/online_store.db\n",
      "M\ttests/.ipynb_checkpoints/test_data_validation-checkpoint.py\n",
      "M\ttests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\n",
      "M\ttests/test_data_validation.py\n",
      "Switched to branch 'dev'\n",
      "Your branch is up to date with 'origin/dev'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "Your branch is up to date with 'origin/dev'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   artifacts/model.joblib\u001b[m\n",
      "\t\u001b[31mmodified:   data/stock_data.parquet.dvc\u001b[m\n",
      "\t\u001b[31mmodified:   feature_repo/online_store.db\u001b[m\n",
      "\t\u001b[31mmodified:   tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\u001b[m\n",
      "\t\u001b[31mmodified:   tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[31mmodified:   tests/test_data_validation.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31mdata/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/stock_data_full.parquet\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git add data/stock_data.parquet.dvc tests/ artifacts/ feature_repo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch dev\n",
      "Your branch is up to date with 'origin/dev'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\t\u001b[32mmodified:   artifacts/model.joblib\u001b[m\n",
      "\t\u001b[32mmodified:   data/stock_data.parquet.dvc\u001b[m\n",
      "\t\u001b[32mmodified:   feature_repo/online_store.db\u001b[m\n",
      "\t\u001b[32mmodified:   tests/.ipynb_checkpoints/test_data_validation-checkpoint.py\u001b[m\n",
      "\t\u001b[32mmodified:   tests/__pycache__/test_data_validation.cpython-310-pytest-8.4.2.pyc\u001b[m\n",
      "\t\u001b[32mmodified:   tests/test_data_validation.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31mWorkbench.ipynb\u001b[m\n",
      "\t\u001b[31mdata/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/stock_data_full.parquet\u001b[m\n",
      "\t\u001b[31mgcp-key.b64.txt\u001b[m\n",
      "\t\u001b[31miitmbs-mlops-a99d6ce657ac.json\u001b[m\n",
      "\t\u001b[31minference.ipynb\u001b[m\n",
      "\t\u001b[31mraw_data/\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev 8ee3c51] Second commit to dev branch. Pytest code changes and second iteration with 300 rows of iris data\n",
      " 6 files changed, 18 insertions(+), 4 deletions(-)\n",
      " rewrite artifacts/model.joblib (80%)\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"Second commit to dev branch. Pytest code changes and second iteration with 300 rows of iris data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit 8ee3c516e1aae4166236354bd2ebed624fb0daaa\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mdev\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Satvik Chandrakar <chandrakarsatvik@gmail.com>\n",
      "Date:   Fri Nov 7 13:06:38 2025 +0000\n",
      "\n",
      "    Second commit to dev branch. Pytest code changes and second iteration with 300 rows of iris data\n",
      "\n",
      "\u001b[33mcommit 95e9b39fc8607322790cb5f32d0a3e8fbaad8230\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/dev\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m\n",
      "Author: Satvik Chandrakar <chandrakarsatvik@gmail.com>\n",
      "Date:   Fri Nov 7 12:46:39 2025 +0000\n",
      "\n",
      "    Commit to both dev and main branch. First iteration done with 150 rows of iris data\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 25, done.\n",
      "Counting objects: 100% (25/25), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (12/12), done.\n",
      "Writing objects: 100% (13/13), 586.63 KiB | 4.85 MiB/s, done.\n",
      "Total 13 (delta 6), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (6/6), completed with 6 local objects.\u001b[K\n",
      "To https://github.com/Satvik-ai/stock_test.git\n",
      "   95e9b39..8ee3c51  dev -> dev\n"
     ]
    }
   ],
   "source": [
    "!git push origin dev"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
